{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify device\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "os.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"]=\"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import json\n",
    "import os\n",
    "import glob\n",
    "import copy\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from termcolor import colored\n",
    "from collections import Counter\n",
    "import cv2\n",
    "import tqdm\n",
    "from termcolor import colored\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (10,10)\n",
    "\n",
    "# change this property\n",
    "NOMEROFF_NET_DIR = os.path.abspath('../../../')\n",
    "sys.path.append(NOMEROFF_NET_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from NomeroffNet.BBoxNpPoints import (NpPointsCraft, \n",
    "                                      getCvZoneRGB, \n",
    "                                      convertCvZonesRGBtoBGR, \n",
    "                                      reshapePoints)\n",
    "from multiline.MultiLineNPExtractor import (CCraft, \n",
    "                                            make_boxes)\n",
    "from NomeroffNet.YoloV5Detector import Detector\n",
    "from NomeroffNet.OptionsDetector import OptionsDetector\n",
    "from NomeroffNet.TextDetector import TextDetector\n",
    "from NomeroffNet.TextPostprocessing import translit_cyrillic_to_latin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskDatasetChecker:\n",
    "    def __init__(self):\n",
    "        self.npPointsCraft = NpPointsCraft()\n",
    "        self.ccraft = CCraft(self.npPointsCraft)\n",
    "        self.npPointsCraft.load()\n",
    "        self.detector = Detector()\n",
    "        self.detector.load()\n",
    "        self.optionsDetector = OptionsDetector()\n",
    "        self.optionsDetector.load()\n",
    "        self.textDetector = TextDetector({\n",
    "            \"eu_ua_2004_2015\": {\n",
    "                \"for_regions\": [\"eu-ua-2015\", \"eu-ua-2004\"],\n",
    "                \"model_path\": \"latest\"\n",
    "            },\n",
    "            \"eu_ua_1995\": {\n",
    "                \"for_regions\": [\"eu-ua-1995\"],\n",
    "                \"model_path\": \"latest\"\n",
    "            },\n",
    "            \"eu\": {\n",
    "                \"for_regions\": [\"eu\"],\n",
    "                \"model_path\": \"latest\"\n",
    "            },\n",
    "            \"ru\": {\n",
    "                \"for_regions\": [\"ru\", \"eu-ua-fake-lnr\", \"eu-ua-fake-dnr\"],\n",
    "                \"model_path\": \"latest\" \n",
    "            },\n",
    "            \"kz\": {\n",
    "                \"for_regions\": [\"kz\"],\n",
    "                \"model_path\": \"latest\"\n",
    "            },\n",
    "            \"ge\": {\n",
    "                \"for_regions\": [\"ge\"],\n",
    "                \"model_path\": \"latest\"\n",
    "            },\n",
    "            \"su\": {\n",
    "                \"for_regions\": [\"su\"],\n",
    "                \"model_path\": \"latest\"\n",
    "            }\n",
    "        })\n",
    "        self.dataset = {}\n",
    "        \n",
    "    def load_dataset(self, json_path):\n",
    "        dataset = {}\n",
    "        print(\"Loading dataset...\")\n",
    "        with open(json_path) as json_file:\n",
    "            data = json.load(json_file)\n",
    "            for p in tqdm.tqdm(data['_via_img_metadata']):\n",
    "                item = data['_via_img_metadata'][p]\n",
    "                filename = item[\"filename\"]\n",
    "                bboxes = []\n",
    "                for region in item['regions']:\n",
    "                    x1 = min(region['shape_attributes']['all_points_x'])\n",
    "                    x2 = max(region['shape_attributes']['all_points_x'])\n",
    "                    y1 = min(region['shape_attributes']['all_points_y'])\n",
    "                    y2 = max(region['shape_attributes']['all_points_y'])\n",
    "                    bboxes.append({\n",
    "                        'x1': x1, \n",
    "                        'x2': x2, \n",
    "                        'y1': y1, \n",
    "                        'y2': y2, \n",
    "                        'xs': region['shape_attributes']['all_points_x'],\n",
    "                        'ys': region['shape_attributes']['all_points_y'],\n",
    "                        'region_name': region['region_attributes'][\"region_name\"].strip(),\n",
    "                        'numberplate': region['region_attributes'][\"np\"].strip(),\n",
    "                    })\n",
    "                dataset[filename] = bboxes\n",
    "        self.dataset = dataset\n",
    "    \n",
    "    def predict(self, image_paths, use_target_box_from_dataset=1, use_option_from_dataset=1, debug=1):\n",
    "        predicted = {}\n",
    "        print(\"Predicting...\")\n",
    "        \n",
    "        counter = Counter()\n",
    "        for img_path in tqdm.tqdm(image_paths):\n",
    "            img = cv2.imread(img_path)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            print(img_path)\n",
    "            print(img.shape)\n",
    "            \n",
    "            dataset_info = self.dataset.get(os.path.basename(img_path), [])\n",
    "            if not use_target_box_from_dataset:\n",
    "                targetBoxes = self.detector.detect_bbox(img)\n",
    "                targetBoxes = targetBoxes\n",
    "            else:\n",
    "                targetBoxes = [[item[\"x1\"], item[\"y1\"], item[\"x2\"], item[\"y2\"]] for item in dataset_info]\n",
    "            all_points = self.npPointsCraft.detect(img, targetBoxes)\n",
    "            all_points = [ps for ps in all_points if len(ps)]\n",
    "\n",
    "            # cut zones\n",
    "            toShowZones = [getCvZoneRGB(img, reshapePoints(rect, 1)) for rect in all_points]\n",
    "            zones = convertCvZonesRGBtoBGR(toShowZones)\n",
    "\n",
    "            # find standart\n",
    "            if not use_option_from_dataset:\n",
    "                region_ids, countLines = self.optionsDetector.predict(zones)\n",
    "                region_names = self.optionsDetector.getRegionLabels(region_ids)\n",
    "            else:\n",
    "                region_names = [item[\"region_name\"] for item in dataset_info]\n",
    "                countLines = [2 for _ in dataset_info]\n",
    "\n",
    "\n",
    "            # convert multiline to one line\n",
    "            image_parts = [img[box[1]:box[3], box[0]:box[2]] \n",
    "                           for box, cl in zip(targetBoxes, countLines) \n",
    "                           if cl > 1]\n",
    "            region_names_rect = [region_name \n",
    "                                   for region_name, cl in zip(region_names, countLines) \n",
    "                                   if cl > 1]\n",
    "            index_rect = [i \n",
    "                          for i, cl in enumerate(countLines) \n",
    "                          if cl > 1]\n",
    "            (zones_rect, \n",
    "             zones_target_points, \n",
    "             zones_mline_boxes) = self.ccraft.multiline_to_one_line(image_parts,\n",
    "                                                                    region_names_rect)\n",
    "            for i, zone in zip(index_rect, zones_rect):\n",
    "                zones[i] = zone\n",
    "\n",
    "            # draw multiline\n",
    "            if debug:\n",
    "                for norm_image, one_line_img, target_points, mline_boxes in zip(image_parts,\n",
    "                                                                    zones_rect, \n",
    "                                                                    zones_target_points, \n",
    "                                                                    zones_mline_boxes):\n",
    "                    make_boxes(norm_image, target_points, (0, 0, 255))\n",
    "                    make_boxes(norm_image, mline_boxes, (255, 0, 0))\n",
    "                    fig, ax = plt.subplots(figsize=(15, 15))\n",
    "                    ax.imshow(cv2.cvtColor(norm_image, cv2.COLOR_BGR2RGB))\n",
    "                    plt.show()\n",
    "                    fig, ax = plt.subplots(figsize=(15, 15))\n",
    "                    ax.imshow(one_line_img)\n",
    "                    plt.show()\n",
    "\n",
    "            # find text with postprocessing by standart  \n",
    "            countLines = [1 for _ in zones]\n",
    "            textArr = self.textDetector.predict(zones, region_names, countLines)\n",
    "            \n",
    "#             print('zones')\n",
    "#             print(zones)\n",
    "\n",
    "#             print('region_names')\n",
    "#             print(region_names)\n",
    "            \n",
    "#             print('countLines')\n",
    "#             print(countLines)            \n",
    "\n",
    "            # append to predicted\n",
    "            predicted[os.path.basename(img_path)] = []\n",
    "            for numberplate, points, region_name in zip(textArr, all_points, region_names):\n",
    "                predicted[os.path.basename(img_path)].append({\n",
    "                    'x1': points[0], \n",
    "                    'x2': points[2], \n",
    "                    'y1': points[1], \n",
    "                    'y2': points[3], \n",
    "                    'region_name': region_name.strip(),\n",
    "                    'numberplate': numberplate.strip(),\n",
    "                })\n",
    "\n",
    "            # dispaly debug info\n",
    "            if debug:\n",
    "                trues = [translit_cyrillic_to_latin(np[\"numberplate\"]) \n",
    "                                       if np[\"region_name\"] != \"su\" else  np[\"numberplate\"]\n",
    "                                       for np in dataset_info]\n",
    "                plt.imshow(img)\n",
    "                plt.show()\n",
    "                print(img_path, colored(trues, \"blue\"))\n",
    "                for zone, numberplate, points, region_name in zip(convertCvZonesRGBtoBGR(zones), \n",
    "                                                                  textArr, \n",
    "                                                                  all_points, \n",
    "                                                                  region_names):\n",
    "                    color = \"yellow\"\n",
    "                    if numberplate in trues:\n",
    "                        counter[\"good\"] += 1\n",
    "                        color = \"green\"\n",
    "                    else:\n",
    "                        counter[\"bad\"] += 1\n",
    "\n",
    "                    plt.imshow(zone)\n",
    "                    plt.show()\n",
    "                    print(colored(json.dumps({\n",
    "                        'region_name': region_name.strip(),\n",
    "                        'numberplate': numberplate.strip(),\n",
    "                    }), color))\n",
    "\n",
    "        \n",
    "        if debug:             \n",
    "            print(colored(str(counter), 'blue'))\n",
    "        return predicted\n",
    "    \n",
    "    def compare(self, \n",
    "                photo_dir = os.path.join(NOMEROFF_NET_DIR, 'dataset/np/'),\n",
    "                json_path = os.path.join(NOMEROFF_NET_DIR, 'dataset/np/via.json'),\n",
    "                use_target_box_from_dataset=1, \n",
    "                use_option_from_dataset=1,\n",
    "                iou_less_than = 0.9,\n",
    "                ocr_acc_less_than = 0.7,\n",
    "                option_acc_less_than = 0.7,\n",
    "                mask_acc_less_than = 0.7):\n",
    "        \"\"\"\n",
    "        TODO: add more comparisons\n",
    "        \"\"\"         \n",
    "        self.load_dataset(json_path)\n",
    "        image_paths = [os.path.join(photo_dir, image_name) for image_name in self.dataset]\n",
    "        self.predict(image_paths,\n",
    "                     use_option_from_dataset=use_option_from_dataset,\n",
    "                     use_target_box_from_dataset=use_target_box_from_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maskDatasetChecker = MaskDatasetChecker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = (20,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num = 5\n",
    "maskDatasetChecker.compare(\n",
    "    photo_dir=f'/var/www/textline_numberplate/data/many_line_{num}',\n",
    "    json_path=f'/var/www/textline_numberplate/data/many_line_{num}/many_lines_{num}new.json',\n",
    "    use_target_box_from_dataset=1, \n",
    "    use_option_from_dataset=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img_test = cv2.imread('/var/www/textline_numberplate/data/many_line_10/276668485.jpeg')\n",
    "#plt.imshow(img_test)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
