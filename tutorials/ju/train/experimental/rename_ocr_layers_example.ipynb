{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8911b19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import copy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from typing import List, Any\n",
    "import pytorch_lightning as pl\n",
    "from datetime import datetime\n",
    "from torchvision.models import resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a528c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change this property\n",
    "NOMEROFF_NET_DIR = os.path.abspath('../../../../')\n",
    "sys.path.append(NOMEROFF_NET_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8bdc47f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nomeroff_net.tools.ocr_tools import plot_loss, print_prediction\n",
    "from nomeroff_net.tools.mcm import get_device_torch\n",
    "from nomeroff_net.tools.ocr_tools import (StrLabelConverter,\n",
    "                                          decode_prediction,\n",
    "                                          decode_batch)\n",
    "from nomeroff_net.nnmodels.ocr_model import NPOcrNet, weights_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1ba9b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30782fbd",
   "metadata": {},
   "source": [
    "# model from branch v3.2\n",
    "https://github.com/ria-com/nomeroff-net/blob/v3.2/nomeroff_net/nnmodels/ocr_model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9bfc6aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlockRNNv3_2(nn.Module):\n",
    "    def __init__(self, in_size, hidden_size, out_size, bidirectional):\n",
    "        super(BlockRNNv3_2, self).__init__()\n",
    "        self.in_size = in_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.out_size = out_size\n",
    "        self.bidirectional = bidirectional\n",
    "        # layers\n",
    "        self.gru = nn.LSTM(in_size, hidden_size, bidirectional=bidirectional, batch_first=True)\n",
    "\n",
    "    def forward(self, batch, add_output=False):\n",
    "        \"\"\"\n",
    "        in array:\n",
    "            batch - [seq_len , batch_size, in_size]\n",
    "        out array:\n",
    "            out - [seq_len , batch_size, out_size]\n",
    "        \"\"\"\n",
    "        outputs, hidden = self.gru(batch)\n",
    "        out_size = int(outputs.size(2) / 2)\n",
    "        if add_output:\n",
    "            outputs = outputs[:, :, :out_size] + outputs[:, :, out_size:]\n",
    "        return outputs\n",
    "\n",
    "\n",
    "class NPOcrNetv3_2(pl.LightningModule):\n",
    "    def __init__(self,\n",
    "                 letters: List = None,\n",
    "                 letters_max: int = 0,\n",
    "                 max_plate_length: int = 8,\n",
    "                 learning_rate: float = 0.02,\n",
    "                 hidden_size: int = 32,\n",
    "                 bidirectional: bool = True,\n",
    "                 label_converter: Any = None,\n",
    "                 val_dataset: Any = None,\n",
    "                 weight_decay: float = 1e-5,\n",
    "                 momentum: float = 0.9,\n",
    "                 clip_norm: int = 5):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.letters = letters\n",
    "        self.learning_rate = learning_rate\n",
    "        self.weight_decay = weight_decay\n",
    "        self.clip_norm = clip_norm\n",
    "        self.momentum = momentum\n",
    "        self.max_plate_length = max_plate_length\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.bidirectional = bidirectional\n",
    "\n",
    "        self.label_converter = label_converter\n",
    "        \n",
    "        # convolutions \n",
    "        resnet = resnet18(pretrained=True)\n",
    "        modules = list(resnet.children())[:-3]\n",
    "        self.resnet = nn.Sequential(*modules)\n",
    "\n",
    "        # RNN + Linear\n",
    "        self.linear1 = nn.Linear(1024, 512)\n",
    "        self.gru1 = BlockRNNv3_2(512, hidden_size, hidden_size,\n",
    "                             bidirectional=bidirectional)\n",
    "        self.gru2 = BlockRNNv3_2(hidden_size, hidden_size, letters_max,\n",
    "                             bidirectional=bidirectional)\n",
    "        self.linear2 = nn.Linear(hidden_size * 2, letters_max)\n",
    "\n",
    "        self.automatic_optimization = True\n",
    "        self.criterion = None\n",
    "        self.val_dataset = val_dataset\n",
    "        self.train_losses = []\n",
    "        self.val_losses = []\n",
    "\n",
    "    def forward(self, batch: torch.float64):\n",
    "        batch_size = batch.size(0)\n",
    "        \n",
    "        # convolutions\n",
    "        batch = self.resnet(batch)\n",
    "\n",
    "        # make sequences of image features\n",
    "        batch = batch.permute(0, 3, 1, 2)\n",
    "        n_channels = batch.size(1)\n",
    "        batch = batch.reshape(batch_size, n_channels, -1)\n",
    "\n",
    "        batch = self.linear1(batch)\n",
    "\n",
    "        # rnn layers\n",
    "        batch = self.gru1(batch, add_output=True)\n",
    "        batch = self.gru2(batch)\n",
    "        # output\n",
    "        batch = self.linear2(batch)\n",
    "        batch = batch.permute(1, 0, 2)\n",
    "        return batch\n",
    "\n",
    "    def init_loss(self):\n",
    "        self.criterion = nn.CTCLoss(blank=0, zero_infinity=True, reduction='mean')\n",
    "\n",
    "    def calculate_loss(self, logits, texts):\n",
    "        if self.criterion is None:\n",
    "            self.init_loss()\n",
    "\n",
    "        # get infomation from prediction\n",
    "        device = logits.device\n",
    "        input_len, batch_size, vocab_size = logits.size()\n",
    "        # encode inputs\n",
    "        logits = logits.log_softmax(2)\n",
    "        encoded_texts, text_lens = self.label_converter.encode(texts)\n",
    "        logits_lens = torch.full(size=(batch_size,), fill_value=input_len, dtype=torch.int32)\n",
    "        # calculate ctc\n",
    "        loss = self.criterion(\n",
    "            logits,\n",
    "            encoded_texts,\n",
    "            logits_lens.to(device),\n",
    "            text_lens)\n",
    "        return loss\n",
    "\n",
    "    def step(self, batch):\n",
    "\n",
    "        x, texts = batch\n",
    "\n",
    "        output = self.forward(x)\n",
    "\n",
    "        loss = self.calculate_loss(output, texts)\n",
    "        return loss\n",
    "\n",
    "    def on_save_checkpoint(self, _):\n",
    "        if self.current_epoch and self.val_dataset:\n",
    "            device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "            print_prediction(self, self.val_dataset, device, self.label_converter)\n",
    "            plot_loss(self.current_epoch, self.train_losses, self.val_losses)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.SGD(\n",
    "            self.parameters(),\n",
    "            lr=self.learning_rate,\n",
    "            nesterov=True,\n",
    "            weight_decay=self.weight_decay,\n",
    "            momentum=self.momentum)\n",
    "        return optimizer\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss = self.step(batch)\n",
    "        self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        tqdm_dict = {\n",
    "            'train_loss': loss,\n",
    "        }\n",
    "        return {\n",
    "            'loss': loss,\n",
    "            'progress_bar': tqdm_dict,\n",
    "            'log': tqdm_dict\n",
    "        }\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss = self.step(batch)\n",
    "        self.log('val_loss', loss, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        tqdm_dict = {\n",
    "            'val_loss': loss,\n",
    "        }\n",
    "        return {\n",
    "            'val_loss': loss,\n",
    "            'progress_bar': tqdm_dict,\n",
    "            'log': tqdm_dict\n",
    "        }\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        loss = self.step(batch)\n",
    "        self.log('test_loss', loss, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        tqdm_dict = {\n",
    "            'test_loss': loss,\n",
    "        }\n",
    "        return {\n",
    "            'test_loss': loss,\n",
    "            'progress_bar': tqdm_dict,\n",
    "            'log': tqdm_dict\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c7150b",
   "metadata": {},
   "source": [
    "# model from branch v3.3\n",
    "https://github.com/ria-com/nomeroff-net/blob/v3.3/nomeroff_net/nnmodels/ocr_model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e4acb3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlockRNNv3_3(nn.Module):\n",
    "    def __init__(self, in_size, hidden_size, out_size, bidirectional, recurrent_nn=nn.LSTM):\n",
    "        super().__init__()\n",
    "        self.in_size = in_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.out_size = out_size\n",
    "        self.bidirectional = bidirectional\n",
    "\n",
    "        # layers\n",
    "        self.rnn = recurrent_nn(in_size, hidden_size, bidirectional=bidirectional, batch_first=True)\n",
    "\n",
    "    def forward(self, batch, add_output=False):\n",
    "        \"\"\"\n",
    "        in array:\n",
    "            batch - [seq_len , batch_size, in_size]\n",
    "        out array:\n",
    "            out - [seq_len , batch_size, out_size]\n",
    "        \"\"\"\n",
    "        outputs, hidden = self.rnn(batch)\n",
    "        out_size = int(outputs.size(2) / 2)\n",
    "        if add_output:\n",
    "            outputs = outputs[:, :, :out_size] + outputs[:, :, out_size:]\n",
    "        return outputs\n",
    "\n",
    "\n",
    "class NPOcrNetv3_3(pl.LightningModule):\n",
    "    def __init__(self,\n",
    "                 letters: List = None,\n",
    "                 letters_max: int = 0,\n",
    "                 max_text_len: int = 8,\n",
    "                 learning_rate: float = 0.02,\n",
    "                 height: int = 50,\n",
    "                 width: int = 200,\n",
    "                 color_channels: int = 3,\n",
    "                 bidirectional: bool = True,\n",
    "                 label_converter: Any = None,\n",
    "                 val_dataset: Any = None,\n",
    "                 weight_decay: float = 1e-5,\n",
    "                 momentum: float = 0.9,\n",
    "                 clip_norm: int = 5,\n",
    "                 hidden_size=32,\n",
    "                 linear_size=512,\n",
    "                 backbone=None):\n",
    "        print(backbone, linear_size, hidden_size, height, width)\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.linear_size = linear_size\n",
    "        self.color_channels = color_channels\n",
    "\n",
    "        self.letters = letters\n",
    "        self.learning_rate = learning_rate\n",
    "        self.weight_decay = weight_decay\n",
    "        self.clip_norm = clip_norm\n",
    "        self.momentum = momentum\n",
    "        self.max_text_len = max_text_len\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.bidirectional = bidirectional\n",
    "\n",
    "        self.label_converter = label_converter\n",
    "\n",
    "        # convolutions\n",
    "        if backbone is None:\n",
    "            backbone = resnet18\n",
    "        conv_nn = backbone(pretrained=True)\n",
    "        if 'resnet' in str(backbone):\n",
    "            conv_modules = list(conv_nn.children())[:-3]\n",
    "        elif 'efficientnet' in str(backbone):\n",
    "            conv_modules = list(conv_nn.children())[:-2]\n",
    "        elif 'shufflenet' in str(backbone):\n",
    "            conv_modules = list(conv_nn.children())[:-3]\n",
    "        else:\n",
    "            raise NotImplementedError(backbone)\n",
    "        self.conv_nn = nn.Sequential(*conv_modules)\n",
    "        _, backbone_c, backbone_h, backbone_w = self.conv_nn(torch.rand((1, color_channels, height, width))).shape\n",
    "\n",
    "        assert backbone_w > max_text_len\n",
    "\n",
    "        # RNN + Linear\n",
    "        self.linear1 = nn.Linear(backbone_c*backbone_h, self.linear_size)\n",
    "        self.recurrent_layer1 = BlockRNNv3_3(self.linear_size, hidden_size, hidden_size,\n",
    "                                         bidirectional=bidirectional)\n",
    "        self.recurrent_layer2 = BlockRNNv3_3(hidden_size, hidden_size, letters_max,\n",
    "                                         bidirectional=bidirectional)\n",
    "\n",
    "        self.linear2 = nn.Linear(hidden_size * 2, letters_max)\n",
    "\n",
    "        self.automatic_optimization = True\n",
    "        self.criterion = None\n",
    "        self.val_dataset = val_dataset\n",
    "        self.train_losses = []\n",
    "        self.val_losses = []\n",
    "\n",
    "    def forward(self, batch: torch.float64):\n",
    "        \"\"\"\n",
    "        forward\n",
    "        \"\"\"\n",
    "        batch_size = batch.size(0)\n",
    "        \n",
    "        # convolutions\n",
    "        batch = self.conv_nn(batch)\n",
    "\n",
    "        # make sequences of image features\n",
    "        batch = batch.permute(0, 3, 1, 2)\n",
    "        n_channels = batch.size(1)\n",
    "        batch = batch.reshape(batch_size, n_channels, -1)\n",
    "        batch = self.linear1(batch)\n",
    "\n",
    "        # rnn layers\n",
    "        batch = self.recurrent_layer1(batch, add_output=True)\n",
    "        batch = self.recurrent_layer2(batch)\n",
    "\n",
    "        # output\n",
    "        batch = self.linear2(batch)\n",
    "        batch = batch.permute(1, 0, 2)\n",
    "        return batch\n",
    "\n",
    "    def init_loss(self):\n",
    "        self.criterion = nn.CTCLoss(blank=0, zero_infinity=True, reduction='mean')\n",
    "\n",
    "    def calculate_loss(self, logits, texts):\n",
    "        if self.criterion is None:\n",
    "            self.init_loss()\n",
    "\n",
    "        # get infomation from prediction\n",
    "        device = logits.device\n",
    "        input_len, batch_size, vocab_size = logits.size()\n",
    "        # encode inputs\n",
    "        logits = logits.log_softmax(2)\n",
    "        encoded_texts, text_lens = self.label_converter.encode(texts)\n",
    "        logits_lens = torch.full(size=(batch_size,), fill_value=input_len, dtype=torch.int32)\n",
    "        # calculate ctc\n",
    "        loss = self.criterion(\n",
    "            logits,\n",
    "            encoded_texts,\n",
    "            logits_lens.to(device),\n",
    "            text_lens)\n",
    "        return loss\n",
    "\n",
    "    def step(self, batch):\n",
    "        x, texts = batch\n",
    "        output = self.forward(x)\n",
    "        loss = self.calculate_loss(output, texts)\n",
    "        return loss\n",
    "\n",
    "    def on_save_checkpoint(self, _):\n",
    "        if self.current_epoch and self.val_dataset:\n",
    "            device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "            print_prediction(self, self.val_dataset, device, self.label_converter)\n",
    "            plot_loss(self.current_epoch, self.train_losses, self.val_losses)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.SGD(\n",
    "            self.parameters(),\n",
    "            lr=self.learning_rate,\n",
    "            nesterov=True,\n",
    "            weight_decay=self.weight_decay,\n",
    "            momentum=self.momentum)\n",
    "        return optimizer\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss = self.step(batch)\n",
    "        self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        tqdm_dict = {\n",
    "            'train_loss': loss,\n",
    "        }\n",
    "        return {\n",
    "            'loss': loss,\n",
    "            'progress_bar': tqdm_dict,\n",
    "            'log': tqdm_dict\n",
    "        }\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss = self.step(batch)\n",
    "        self.log('val_loss', loss, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        tqdm_dict = {\n",
    "            'val_loss': loss,\n",
    "        }\n",
    "        return {\n",
    "            'val_loss': loss,\n",
    "            'progress_bar': tqdm_dict,\n",
    "            'log': tqdm_dict\n",
    "        }\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        loss = self.step(batch)\n",
    "        self.log('test_loss', loss, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        tqdm_dict = {\n",
    "            'test_loss': loss,\n",
    "        }\n",
    "        return {\n",
    "            'test_loss': loss,\n",
    "            'progress_bar': tqdm_dict,\n",
    "            'log': tqdm_dict\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122bded3",
   "metadata": {},
   "source": [
    "# Convert chekpoint keys v3.2 -> v3.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf51f7a4",
   "metadata": {},
   "source": [
    "## am"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "da460a29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None 512 32 50 200\n"
     ]
    }
   ],
   "source": [
    "DATASET_NAME = \"am\"\n",
    "VERSION = f\"{datetime.now().strftime('%Y_%m_%d')}\"\n",
    "\n",
    "RESULT_MODEL_PATH = os.path.join(NOMEROFF_NET_DIR, \n",
    "                                 \"data/models/\", \n",
    "                                 'anpr_ocr_{}_{}.ckpt'.format(DATASET_NAME, VERSION))\n",
    "letters = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H',\n",
    "           'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z']\n",
    "\n",
    "max_plate_length = 7\n",
    "label_converter = StrLabelConverter(\"\".join(letters), max_plate_length)\n",
    "\n",
    "modelv3_2 = NPOcrNetv3_2.load_from_checkpoint(\"https://nomeroff.net.ua/models/ocr/am/torch/model_v3.1/anpr_ocr_am_2022_03_28_pytorch_lightning.ckpt\",\n",
    "                                              map_location=torch.device('cpu'),\n",
    "                                              letters=letters,\n",
    "                                              letters_max=len(letters) + 1,\n",
    "                                              label_converter=label_converter,\n",
    "                                              max_plate_length=max_plate_length)\n",
    "\n",
    "modelv3_3 = NPOcrNetv3_3(letters,\n",
    "                         letters_max=len(letters) + 1,\n",
    "                         label_converter=label_converter,\n",
    "                         max_text_len=max_plate_length)\n",
    "\n",
    "state_dict_v3_2 = modelv3_2.state_dict()\n",
    "state_dict_v3_3 = copy.deepcopy(state_dict_v3_2)\n",
    "for key in state_dict_v3_2:\n",
    "    if 'resnet' in key:\n",
    "        key_v3_3 = key.replace('resnet', 'conv_nn')\n",
    "        state_dict_v3_3[key_v3_3] = state_dict_v3_3.pop(key)\n",
    "    elif 'gru' in key:\n",
    "        key_v3_3 = key.replace('.gru.', '.rnn.')\n",
    "        key_v3_3 = key_v3_3.replace('gru', 'recurrent_layer')\n",
    "        state_dict_v3_3[key_v3_3] = state_dict_v3_3.pop(key)\n",
    "        \n",
    "modelv3_3.load_state_dict(state_dict_v3_3)\n",
    "torch.save({\"state_dict\": modelv3_3.state_dict()}, RESULT_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966dea0f",
   "metadata": {},
   "source": [
    "## by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ad1a1b70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://nomeroff.net.ua/models/ocr/by/torch/model_v3.1/anpr_ocr_by_2022_03_28_pytorch_lightning.ckpt\" to /home/dmitroprobachay/.cache/torch/hub/checkpoints/anpr_ocr_by_2022_03_28_pytorch_lightning.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2cbfa4f34c64930b5f36a6c04c70ef7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/13.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None 512 32 50 200\n"
     ]
    }
   ],
   "source": [
    "DATASET_NAME = \"by\"\n",
    "VERSION = f\"{datetime.now().strftime('%Y_%m_%d')}\"\n",
    "\n",
    "RESULT_MODEL_PATH = os.path.join(NOMEROFF_NET_DIR, \n",
    "                                 \"data/models/\", \n",
    "                                 'anpr_ocr_{}_{}.ckpt'.format(DATASET_NAME, VERSION))\n",
    "letters = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'E', 'H', 'I',\n",
    "           'K', 'M', 'O', 'P', 'T', 'X']\n",
    "\n",
    "max_plate_length = 7\n",
    "label_converter = StrLabelConverter(\"\".join(letters), max_plate_length)\n",
    "\n",
    "modelv3_2 = NPOcrNetv3_2.load_from_checkpoint(\"https://nomeroff.net.ua/models/ocr/by/torch/model_v3.1/anpr_ocr_by_2022_03_28_pytorch_lightning.ckpt\",\n",
    "                                              map_location=torch.device('cpu'),\n",
    "                                              letters=letters,\n",
    "                                              letters_max=len(letters) + 1,\n",
    "                                              label_converter=label_converter,\n",
    "                                              max_plate_length=max_plate_length)\n",
    "\n",
    "modelv3_3 = NPOcrNetv3_3(letters,\n",
    "                         letters_max=len(letters) + 1,\n",
    "                         label_converter=label_converter,\n",
    "                         max_text_len=max_plate_length)\n",
    "\n",
    "state_dict_v3_2 = modelv3_2.state_dict()\n",
    "state_dict_v3_3 = copy.deepcopy(state_dict_v3_2)\n",
    "for key in state_dict_v3_2:\n",
    "    if 'resnet' in key:\n",
    "        key_v3_3 = key.replace('resnet', 'conv_nn')\n",
    "        state_dict_v3_3[key_v3_3] = state_dict_v3_3.pop(key)\n",
    "    elif 'gru' in key:\n",
    "        key_v3_3 = key.replace('.gru.', '.rnn.')\n",
    "        key_v3_3 = key_v3_3.replace('gru', 'recurrent_layer')\n",
    "        state_dict_v3_3[key_v3_3] = state_dict_v3_3.pop(key)\n",
    "        \n",
    "modelv3_3.load_state_dict(state_dict_v3_3)\n",
    "torch.save({\"state_dict\": modelv3_3.state_dict()}, RESULT_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab71a70",
   "metadata": {},
   "source": [
    "## eu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "996ea799",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://nomeroff.net.ua/models/ocr/eu/torch/model_v3.1/anpr_ocr_eu_2022_03_28_pytorch_lightning.ckpt\" to /home/dmitroprobachay/.cache/torch/hub/checkpoints/anpr_ocr_eu_2022_03_28_pytorch_lightning.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "895948dc210742bc981be9b9e4a7103c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/13.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None 512 32 50 200\n"
     ]
    }
   ],
   "source": [
    "DATASET_NAME = \"eu\"\n",
    "VERSION = f\"{datetime.now().strftime('%Y_%m_%d')}\"\n",
    "\n",
    "RESULT_MODEL_PATH = os.path.join(NOMEROFF_NET_DIR, \n",
    "                                 \"data/models/\", \n",
    "                                 'anpr_ocr_{}_{}.ckpt'.format(DATASET_NAME, VERSION))\n",
    "letters = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\",\n",
    "           \"J\", \"K\", \"L\", \"M\", \"N\", \"O\", \"P\", \"Q\", \"R\", \"S\", \"T\", \"U\", \"V\", \"W\", \"X\", \"Y\", \"Z\"]\n",
    "\n",
    "max_plate_length = 9\n",
    "label_converter = StrLabelConverter(\"\".join(letters), max_plate_length)\n",
    "\n",
    "modelv3_2 = NPOcrNetv3_2.load_from_checkpoint(\"https://nomeroff.net.ua/models/ocr/eu/torch/model_v3.1/anpr_ocr_eu_2022_03_28_pytorch_lightning.ckpt\",\n",
    "                                              map_location=torch.device('cpu'),\n",
    "                                              letters=letters,\n",
    "                                              letters_max=len(letters) + 1,\n",
    "                                              label_converter=label_converter,\n",
    "                                              max_plate_length=max_plate_length)\n",
    "\n",
    "modelv3_3 = NPOcrNetv3_3(letters,\n",
    "                         letters_max=len(letters) + 1,\n",
    "                         label_converter=label_converter,\n",
    "                         max_text_len=max_plate_length)\n",
    "\n",
    "state_dict_v3_2 = modelv3_2.state_dict()\n",
    "state_dict_v3_3 = copy.deepcopy(state_dict_v3_2)\n",
    "for key in state_dict_v3_2:\n",
    "    if 'resnet' in key:\n",
    "        key_v3_3 = key.replace('resnet', 'conv_nn')\n",
    "        state_dict_v3_3[key_v3_3] = state_dict_v3_3.pop(key)\n",
    "    elif 'gru' in key:\n",
    "        key_v3_3 = key.replace('.gru.', '.rnn.')\n",
    "        key_v3_3 = key_v3_3.replace('gru', 'recurrent_layer')\n",
    "        state_dict_v3_3[key_v3_3] = state_dict_v3_3.pop(key)\n",
    "        \n",
    "modelv3_3.load_state_dict(state_dict_v3_3)\n",
    "torch.save({\"state_dict\": modelv3_3.state_dict()}, RESULT_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ecff80f",
   "metadata": {},
   "source": [
    "## eu_ua_1995"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6c5f6182",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://nomeroff.net.ua/models/ocr/ua-1995/torch/model_v3.1/anpr_ocr_eu_ua_1995_2022_03_28_pytorch_lightning.ckpt\" to /home/dmitroprobachay/.cache/torch/hub/checkpoints/anpr_ocr_eu_ua_1995_2022_03_28_pytorch_lightning.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b691a7a488564e79be4e707d06d665f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/13.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None 512 32 50 200\n"
     ]
    }
   ],
   "source": [
    "DATASET_NAME = \"eu_ua_1995\"\n",
    "VERSION = f\"{datetime.now().strftime('%Y_%m_%d')}\"\n",
    "\n",
    "RESULT_MODEL_PATH = os.path.join(NOMEROFF_NET_DIR, \n",
    "                                 \"data/models/\", \n",
    "                                 'anpr_ocr_{}_{}.ckpt'.format(DATASET_NAME, VERSION))\n",
    "letters = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'E', 'H', 'I', 'K', 'M',\n",
    "           'O', 'P', 'T', 'X']\n",
    "\n",
    "max_plate_length = 8\n",
    "label_converter = StrLabelConverter(\"\".join(letters), max_plate_length)\n",
    "\n",
    "modelv3_2 = NPOcrNetv3_2.load_from_checkpoint(\"https://nomeroff.net.ua/models/ocr/ua-1995/torch/model_v3.1/anpr_ocr_eu_ua_1995_2022_03_28_pytorch_lightning.ckpt\",\n",
    "                                              map_location=torch.device('cpu'),\n",
    "                                              letters=letters,\n",
    "                                              letters_max=len(letters) + 1,\n",
    "                                              label_converter=label_converter,\n",
    "                                              max_plate_length=max_plate_length)\n",
    "\n",
    "modelv3_3 = NPOcrNetv3_3(letters,\n",
    "                         letters_max=len(letters) + 1,\n",
    "                         label_converter=label_converter,\n",
    "                         max_text_len=max_plate_length)\n",
    "\n",
    "state_dict_v3_2 = modelv3_2.state_dict()\n",
    "state_dict_v3_3 = copy.deepcopy(state_dict_v3_2)\n",
    "for key in state_dict_v3_2:\n",
    "    if 'resnet' in key:\n",
    "        key_v3_3 = key.replace('resnet', 'conv_nn')\n",
    "        state_dict_v3_3[key_v3_3] = state_dict_v3_3.pop(key)\n",
    "    elif 'gru' in key:\n",
    "        key_v3_3 = key.replace('.gru.', '.rnn.')\n",
    "        key_v3_3 = key_v3_3.replace('gru', 'recurrent_layer')\n",
    "        state_dict_v3_3[key_v3_3] = state_dict_v3_3.pop(key)\n",
    "        \n",
    "modelv3_3.load_state_dict(state_dict_v3_3)\n",
    "torch.save({\"state_dict\": modelv3_3.state_dict()}, RESULT_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc23974",
   "metadata": {},
   "source": [
    "## eu_ua_2004_2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9c755805",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://nomeroff.net.ua/models/ocr/ua/torch/model_v3.1/anpr_ocr_eu_2004_2015_2022_10_29_pytorch_lightning.ckpt\" to /home/dmitroprobachay/.cache/torch/hub/checkpoints/anpr_ocr_eu_2004_2015_2022_10_29_pytorch_lightning.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7c0f96291ce406e8da3ccf7398cb96b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/26.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None 512 32 50 200\n"
     ]
    }
   ],
   "source": [
    "DATASET_NAME = \"eu_ua_2004_2015\"\n",
    "VERSION = f\"{datetime.now().strftime('%Y_%m_%d')}\"\n",
    "\n",
    "RESULT_MODEL_PATH = os.path.join(NOMEROFF_NET_DIR, \n",
    "                                 \"data/models/\", \n",
    "                                 'anpr_ocr_{}_{}.ckpt'.format(DATASET_NAME, VERSION))\n",
    "letters = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \n",
    "           \"I\", \"K\", \"M\", \"O\", \"P\", \"T\", \"X\", \"Y\", \"Z\"]\n",
    "\n",
    "max_plate_length = 8\n",
    "label_converter = StrLabelConverter(\"\".join(letters), max_plate_length)\n",
    "\n",
    "modelv3_2 = NPOcrNetv3_2.load_from_checkpoint(\"https://nomeroff.net.ua/models/ocr/ua/torch/model_v3.1/anpr_ocr_eu_2004_2015_2022_10_29_pytorch_lightning.ckpt\",\n",
    "                                              map_location=torch.device('cpu'),\n",
    "                                              letters=letters,\n",
    "                                              letters_max=len(letters) + 1,\n",
    "                                              label_converter=label_converter,\n",
    "                                              max_plate_length=max_plate_length)\n",
    "\n",
    "modelv3_3 = NPOcrNetv3_3(letters,\n",
    "                         letters_max=len(letters) + 1,\n",
    "                         label_converter=label_converter,\n",
    "                         max_text_len=max_plate_length)\n",
    "\n",
    "state_dict_v3_2 = modelv3_2.state_dict()\n",
    "state_dict_v3_3 = copy.deepcopy(state_dict_v3_2)\n",
    "for key in state_dict_v3_2:\n",
    "    if 'resnet' in key:\n",
    "        key_v3_3 = key.replace('resnet', 'conv_nn')\n",
    "        state_dict_v3_3[key_v3_3] = state_dict_v3_3.pop(key)\n",
    "    elif 'gru' in key:\n",
    "        key_v3_3 = key.replace('.gru.', '.rnn.')\n",
    "        key_v3_3 = key_v3_3.replace('gru', 'recurrent_layer')\n",
    "        state_dict_v3_3[key_v3_3] = state_dict_v3_3.pop(key)\n",
    "        \n",
    "modelv3_3.load_state_dict(state_dict_v3_3)\n",
    "torch.save({\"state_dict\": modelv3_3.state_dict()}, RESULT_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ebfcb19",
   "metadata": {},
   "source": [
    "## ge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5c290480",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://nomeroff.net.ua/models/ocr/ge/torch/model_v3.1/anpr_ocr_ge_2022_03_28_pytorch_lightning.ckpt\" to /home/dmitroprobachay/.cache/torch/hub/checkpoints/anpr_ocr_ge_2022_03_28_pytorch_lightning.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3da15996aa54412aa0ad543198bfc3b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/13.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None 512 32 50 200\n"
     ]
    }
   ],
   "source": [
    "DATASET_NAME = \"ge\"\n",
    "VERSION = f\"{datetime.now().strftime('%Y_%m_%d')}\"\n",
    "\n",
    "RESULT_MODEL_PATH = os.path.join(NOMEROFF_NET_DIR, \n",
    "                                 \"data/models/\", \n",
    "                                 'anpr_ocr_{}_{}.ckpt'.format(DATASET_NAME, VERSION))\n",
    "letters = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\",\n",
    "           \"J\", \"K\", \"L\", \"M\", \"N\", \"P\", \"Q\", \"R\", \"S\", \"T\", \"U\", \"V\", \"W\", \"X\", \"Y\", \"Z\"]\n",
    "\n",
    "max_plate_length = 8\n",
    "label_converter = StrLabelConverter(\"\".join(letters), max_plate_length)\n",
    "\n",
    "modelv3_2 = NPOcrNetv3_2.load_from_checkpoint(\"https://nomeroff.net.ua/models/ocr/ge/torch/model_v3.1/anpr_ocr_ge_2022_03_28_pytorch_lightning.ckpt\",\n",
    "                                              map_location=torch.device('cpu'),\n",
    "                                              letters=letters,\n",
    "                                              letters_max=len(letters) + 1,\n",
    "                                              label_converter=label_converter,\n",
    "                                              max_plate_length=max_plate_length)\n",
    "\n",
    "modelv3_3 = NPOcrNetv3_3(letters,\n",
    "                         letters_max=len(letters) + 1,\n",
    "                         label_converter=label_converter,\n",
    "                         max_text_len=max_plate_length)\n",
    "\n",
    "state_dict_v3_2 = modelv3_2.state_dict()\n",
    "state_dict_v3_3 = copy.deepcopy(state_dict_v3_2)\n",
    "for key in state_dict_v3_2:\n",
    "    if 'resnet' in key:\n",
    "        key_v3_3 = key.replace('resnet', 'conv_nn')\n",
    "        state_dict_v3_3[key_v3_3] = state_dict_v3_3.pop(key)\n",
    "    elif 'gru' in key:\n",
    "        key_v3_3 = key.replace('.gru.', '.rnn.')\n",
    "        key_v3_3 = key_v3_3.replace('gru', 'recurrent_layer')\n",
    "        state_dict_v3_3[key_v3_3] = state_dict_v3_3.pop(key)\n",
    "        \n",
    "modelv3_3.load_state_dict(state_dict_v3_3)\n",
    "torch.save({\"state_dict\": modelv3_3.state_dict()}, RESULT_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2d7155",
   "metadata": {},
   "source": [
    "## kg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "bd27504d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://nomeroff.net.ua/models/ocr/kg/torch/model_v3.1/anpr_ocr_kg_2022_03_28_pytorch_lightning.ckpt\" to /home/dmitroprobachay/.cache/torch/hub/checkpoints/anpr_ocr_kg_2022_03_28_pytorch_lightning.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43a620dc92254085b7bd857eccae1e4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/13.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None 512 32 50 200\n"
     ]
    }
   ],
   "source": [
    "DATASET_NAME = \"kg\"\n",
    "VERSION = f\"{datetime.now().strftime('%Y_%m_%d')}\"\n",
    "\n",
    "RESULT_MODEL_PATH = os.path.join(NOMEROFF_NET_DIR, \n",
    "                                 \"data/models/\", \n",
    "                                 'anpr_ocr_{}_{}.ckpt'.format(DATASET_NAME, VERSION))\n",
    "letters = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\",\n",
    "           \"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\", \"J\",\n",
    "           \"K\", \"L\", \"M\", \"N\", \"O\", \"P\", \"Q\", \"R\", \"S\", \"T\",\n",
    "           \"U\", \"V\", \"W\", \"X\", \"Y\", \"Z\"]\n",
    "\n",
    "max_plate_length = 8\n",
    "label_converter = StrLabelConverter(\"\".join(letters), max_plate_length)\n",
    "\n",
    "modelv3_2 = NPOcrNetv3_2.load_from_checkpoint(\"https://nomeroff.net.ua/models/ocr/kg/torch/model_v3.1/anpr_ocr_kg_2022_03_28_pytorch_lightning.ckpt\",\n",
    "                                              map_location=torch.device('cpu'),\n",
    "                                              letters=letters,\n",
    "                                              letters_max=len(letters) + 1,\n",
    "                                              label_converter=label_converter,\n",
    "                                              max_plate_length=max_plate_length)\n",
    "\n",
    "modelv3_3 = NPOcrNetv3_3(letters,\n",
    "                         letters_max=len(letters) + 1,\n",
    "                         label_converter=label_converter,\n",
    "                         max_text_len=max_plate_length)\n",
    "\n",
    "state_dict_v3_2 = modelv3_2.state_dict()\n",
    "state_dict_v3_3 = copy.deepcopy(state_dict_v3_2)\n",
    "for key in state_dict_v3_2:\n",
    "    if 'resnet' in key:\n",
    "        key_v3_3 = key.replace('resnet', 'conv_nn')\n",
    "        state_dict_v3_3[key_v3_3] = state_dict_v3_3.pop(key)\n",
    "    elif 'gru' in key:\n",
    "        key_v3_3 = key.replace('.gru.', '.rnn.')\n",
    "        key_v3_3 = key_v3_3.replace('gru', 'recurrent_layer')\n",
    "        state_dict_v3_3[key_v3_3] = state_dict_v3_3.pop(key)\n",
    "        \n",
    "modelv3_3.load_state_dict(state_dict_v3_3)\n",
    "torch.save({\"state_dict\": modelv3_3.state_dict()}, RESULT_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac1fce2",
   "metadata": {},
   "source": [
    "## kz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "be995ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://nomeroff.net.ua/models/ocr/kz/torch/model_v3.1/anpr_ocr_kz_2022_03_28_pytorch_lightning.ckpt\" to /home/dmitroprobachay/.cache/torch/hub/checkpoints/anpr_ocr_kz_2022_03_28_pytorch_lightning.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a587781ea82049bbac437fdc2b803a6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/13.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None 512 32 50 200\n"
     ]
    }
   ],
   "source": [
    "DATASET_NAME = \"kz\"\n",
    "VERSION = f\"{datetime.now().strftime('%Y_%m_%d')}\"\n",
    "\n",
    "RESULT_MODEL_PATH = os.path.join(NOMEROFF_NET_DIR, \n",
    "                                 \"data/models/\", \n",
    "                                 'anpr_ocr_{}_{}.ckpt'.format(DATASET_NAME, VERSION))\n",
    "letters = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\",\n",
    "           \"I\", \"J\", \"K\", \"L\", \"M\", \"N\", \"O\", \"P\", \"Q\", \"R\", \"S\", \"T\", \"U\", \"V\", \"W\", \"X\", \"Y\", \"Z\"]\n",
    "\n",
    "max_plate_length = 6\n",
    "label_converter = StrLabelConverter(\"\".join(letters), max_plate_length)\n",
    "\n",
    "modelv3_2 = NPOcrNetv3_2.load_from_checkpoint(\"https://nomeroff.net.ua/models/ocr/kz/torch/model_v3.1/anpr_ocr_kz_2022_03_28_pytorch_lightning.ckpt\",\n",
    "                                              map_location=torch.device('cpu'),\n",
    "                                              letters=letters,\n",
    "                                              letters_max=len(letters) + 1,\n",
    "                                              label_converter=label_converter,\n",
    "                                              max_plate_length=max_plate_length)\n",
    "\n",
    "modelv3_3 = NPOcrNetv3_3(letters,\n",
    "                         letters_max=len(letters) + 1,\n",
    "                         label_converter=label_converter,\n",
    "                         max_text_len=max_plate_length)\n",
    "\n",
    "state_dict_v3_2 = modelv3_2.state_dict()\n",
    "state_dict_v3_3 = copy.deepcopy(state_dict_v3_2)\n",
    "for key in state_dict_v3_2:\n",
    "    if 'resnet' in key:\n",
    "        key_v3_3 = key.replace('resnet', 'conv_nn')\n",
    "        state_dict_v3_3[key_v3_3] = state_dict_v3_3.pop(key)\n",
    "    elif 'gru' in key:\n",
    "        key_v3_3 = key.replace('.gru.', '.rnn.')\n",
    "        key_v3_3 = key_v3_3.replace('gru', 'recurrent_layer')\n",
    "        state_dict_v3_3[key_v3_3] = state_dict_v3_3.pop(key)\n",
    "        \n",
    "modelv3_3.load_state_dict(state_dict_v3_3)\n",
    "torch.save({\"state_dict\": modelv3_3.state_dict()}, RESULT_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2a05d6",
   "metadata": {},
   "source": [
    "## md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d9e17b0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://nomeroff.net.ua/models/ocr/md/torch/model_v3.1/anpr_ocr_md_2022_07_01_pytorch_lightning.ckpt\" to /home/dmitroprobachay/.cache/torch/hub/checkpoints/anpr_ocr_md_2022_07_01_pytorch_lightning.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ddd5e3fa0f44fe3b3571cd6075acf44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/26.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None 512 32 50 200\n"
     ]
    }
   ],
   "source": [
    "DATASET_NAME = \"md\"\n",
    "VERSION = f\"{datetime.now().strftime('%Y_%m_%d')}\"\n",
    "\n",
    "RESULT_MODEL_PATH = os.path.join(NOMEROFF_NET_DIR, \n",
    "                                 \"data/models/\", \n",
    "                                 'anpr_ocr_{}_{}.ckpt'.format(DATASET_NAME, VERSION))\n",
    "letters = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\",\n",
    "           \"J\", \"K\", \"L\", \"M\", \"N\", \"O\", \"P\", \"Q\", \"R\", \"S\", \"T\", \"U\", \"V\", \"W\", \"X\", \"Y\", \"Z\"]\n",
    "\n",
    "max_plate_length = 7\n",
    "label_converter = StrLabelConverter(\"\".join(letters), max_plate_length)\n",
    "\n",
    "modelv3_2 = NPOcrNetv3_2.load_from_checkpoint(\"https://nomeroff.net.ua/models/ocr/md/torch/model_v3.1/anpr_ocr_md_2022_07_01_pytorch_lightning.ckpt\",\n",
    "                                              map_location=torch.device('cpu'),\n",
    "                                              letters=letters,\n",
    "                                              letters_max=len(letters) + 1,\n",
    "                                              label_converter=label_converter,\n",
    "                                              max_plate_length=max_plate_length)\n",
    "\n",
    "modelv3_3 = NPOcrNetv3_3(letters,\n",
    "                         letters_max=len(letters) + 1,\n",
    "                         label_converter=label_converter,\n",
    "                         max_text_len=max_plate_length)\n",
    "\n",
    "state_dict_v3_2 = modelv3_2.state_dict()\n",
    "state_dict_v3_3 = copy.deepcopy(state_dict_v3_2)\n",
    "for key in state_dict_v3_2:\n",
    "    if 'resnet' in key:\n",
    "        key_v3_3 = key.replace('resnet', 'conv_nn')\n",
    "        state_dict_v3_3[key_v3_3] = state_dict_v3_3.pop(key)\n",
    "    elif 'gru' in key:\n",
    "        key_v3_3 = key.replace('.gru.', '.rnn.')\n",
    "        key_v3_3 = key_v3_3.replace('gru', 'recurrent_layer')\n",
    "        state_dict_v3_3[key_v3_3] = state_dict_v3_3.pop(key)\n",
    "        \n",
    "modelv3_3.load_state_dict(state_dict_v3_3)\n",
    "torch.save({\"state_dict\": modelv3_3.state_dict()}, RESULT_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf10492",
   "metadata": {},
   "source": [
    "## ru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "93bd9c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://nomeroff.net.ua/models/ocr/ru/torch/model_v3.1/anpr_ocr_ru_2022_03_28_pytorch_lightning.ckpt\" to /home/dmitroprobachay/.cache/torch/hub/checkpoints/anpr_ocr_ru_2022_03_28_pytorch_lightning.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac44c4ed2776460aa1b79dc27abf830e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/13.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None 512 32 50 200\n"
     ]
    }
   ],
   "source": [
    "DATASET_NAME = \"ru\"\n",
    "VERSION = f\"{datetime.now().strftime('%Y_%m_%d')}\"\n",
    "\n",
    "RESULT_MODEL_PATH = os.path.join(NOMEROFF_NET_DIR, \n",
    "                                 \"data/models/\", \n",
    "                                 'anpr_ocr_{}_{}.ckpt'.format(DATASET_NAME, VERSION))\n",
    "letters = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"A\", \"B\", \"C\", \"E\", \"H\", \"K\", \"M\", \"O\",\n",
    "           \"P\", \"T\", \"X\", \"Y\"]\n",
    "\n",
    "max_plate_length = 9\n",
    "label_converter = StrLabelConverter(\"\".join(letters), max_plate_length)\n",
    "\n",
    "modelv3_2 = NPOcrNetv3_2.load_from_checkpoint(\"https://nomeroff.net.ua/models/ocr/ru/torch/model_v3.1/anpr_ocr_ru_2022_03_28_pytorch_lightning.ckpt\",\n",
    "                                              map_location=torch.device('cpu'),\n",
    "                                              letters=letters,\n",
    "                                              letters_max=len(letters) + 1,\n",
    "                                              label_converter=label_converter,\n",
    "                                              max_plate_length=max_plate_length)\n",
    "\n",
    "modelv3_3 = NPOcrNetv3_3(letters,\n",
    "                         letters_max=len(letters) + 1,\n",
    "                         label_converter=label_converter,\n",
    "                         max_text_len=max_plate_length)\n",
    "\n",
    "state_dict_v3_2 = modelv3_2.state_dict()\n",
    "state_dict_v3_3 = copy.deepcopy(state_dict_v3_2)\n",
    "for key in state_dict_v3_2:\n",
    "    if 'resnet' in key:\n",
    "        key_v3_3 = key.replace('resnet', 'conv_nn')\n",
    "        state_dict_v3_3[key_v3_3] = state_dict_v3_3.pop(key)\n",
    "    elif 'gru' in key:\n",
    "        key_v3_3 = key.replace('.gru.', '.rnn.')\n",
    "        key_v3_3 = key_v3_3.replace('gru', 'recurrent_layer')\n",
    "        state_dict_v3_3[key_v3_3] = state_dict_v3_3.pop(key)\n",
    "        \n",
    "modelv3_3.load_state_dict(state_dict_v3_3)\n",
    "torch.save({\"state_dict\": modelv3_3.state_dict()}, RESULT_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15b43d2",
   "metadata": {},
   "source": [
    "## ru_military"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a4f68115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None 512 32 50 200\n"
     ]
    }
   ],
   "source": [
    "DATASET_NAME = \"ru_military\"\n",
    "VERSION = f\"{datetime.now().strftime('%Y_%m_%d')}\"\n",
    "\n",
    "RESULT_MODEL_PATH = os.path.join(NOMEROFF_NET_DIR, \n",
    "                                 \"data/models/\", \n",
    "                                 'anpr_ocr_{}_{}.ckpt'.format(DATASET_NAME, VERSION))\n",
    "letters = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"A\", \"B\", \"C\", \"E\", \"H\", \"K\", \"M\", \"O\",\n",
    "           \"P\", \"T\", \"X\", \"Y\"]\n",
    "\n",
    "max_plate_length = 8\n",
    "label_converter = StrLabelConverter(\"\".join(letters), max_plate_length)\n",
    "\n",
    "modelv3_2 = NPOcrNetv3_2.load_from_checkpoint(\"https://nomeroff.net.ua/models/ocr/ru-military/torch/model_v3.1/anpr_ocr_ru_military_2022_03_28_pytorch_lightning.ckpt\",\n",
    "                                              map_location=torch.device('cpu'),\n",
    "                                              letters=letters,\n",
    "                                              letters_max=len(letters) + 1,\n",
    "                                              label_converter=label_converter,\n",
    "                                              max_plate_length=max_plate_length)\n",
    "\n",
    "modelv3_3 = NPOcrNetv3_3(letters,\n",
    "                         letters_max=len(letters) + 1,\n",
    "                         label_converter=label_converter,\n",
    "                         max_text_len=max_plate_length)\n",
    "\n",
    "state_dict_v3_2 = modelv3_2.state_dict()\n",
    "state_dict_v3_3 = copy.deepcopy(state_dict_v3_2)\n",
    "for key in state_dict_v3_2:\n",
    "    if 'resnet' in key:\n",
    "        key_v3_3 = key.replace('resnet', 'conv_nn')\n",
    "        state_dict_v3_3[key_v3_3] = state_dict_v3_3.pop(key)\n",
    "    elif 'gru' in key:\n",
    "        key_v3_3 = key.replace('.gru.', '.rnn.')\n",
    "        key_v3_3 = key_v3_3.replace('gru', 'recurrent_layer')\n",
    "        state_dict_v3_3[key_v3_3] = state_dict_v3_3.pop(key)\n",
    "        \n",
    "modelv3_3.load_state_dict(state_dict_v3_3)\n",
    "torch.save({\"state_dict\": modelv3_3.state_dict()}, RESULT_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f52a41",
   "metadata": {},
   "source": [
    "## su"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "229a0de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://nomeroff.net.ua/models/ocr/su/torch/model_v3.1/anpr_ocr_su_2022_03_28_pytorch_lightning.ckpt\" to /home/dmitroprobachay/.cache/torch/hub/checkpoints/anpr_ocr_su_2022_03_28_pytorch_lightning.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8946f8f91a0e478b85f817e81310b9d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/13.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None 512 32 50 200\n"
     ]
    }
   ],
   "source": [
    "DATASET_NAME = \"su\"\n",
    "VERSION = f\"{datetime.now().strftime('%Y_%m_%d')}\"\n",
    "\n",
    "RESULT_MODEL_PATH = os.path.join(NOMEROFF_NET_DIR, \n",
    "                                 \"data/models/\", \n",
    "                                 'anpr_ocr_{}_{}.ckpt'.format(DATASET_NAME, VERSION))\n",
    "letters = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9',\n",
    "           '', '', '', '', '', '', '', '', '', '',\n",
    "           '', '', '', '', '', '', '', '', '', '',\n",
    "           '', '', '', '', '', '', '', '', '']\n",
    "\n",
    "max_plate_length = 7\n",
    "label_converter = StrLabelConverter(\"\".join(letters), max_plate_length)\n",
    "\n",
    "modelv3_2 = NPOcrNetv3_2.load_from_checkpoint(\"https://nomeroff.net.ua/models/ocr/su/torch/model_v3.1/anpr_ocr_su_2022_03_28_pytorch_lightning.ckpt\",\n",
    "                                              map_location=torch.device('cpu'),\n",
    "                                              letters=letters,\n",
    "                                              letters_max=len(letters) + 1,\n",
    "                                              label_converter=label_converter,\n",
    "                                              max_plate_length=max_plate_length)\n",
    "\n",
    "modelv3_3 = NPOcrNetv3_3(letters,\n",
    "                         letters_max=len(letters) + 1,\n",
    "                         label_converter=label_converter,\n",
    "                         max_text_len=max_plate_length)\n",
    "\n",
    "state_dict_v3_2 = modelv3_2.state_dict()\n",
    "state_dict_v3_3 = copy.deepcopy(state_dict_v3_2)\n",
    "for key in state_dict_v3_2:\n",
    "    if 'resnet' in key:\n",
    "        key_v3_3 = key.replace('resnet', 'conv_nn')\n",
    "        state_dict_v3_3[key_v3_3] = state_dict_v3_3.pop(key)\n",
    "    elif 'gru' in key:\n",
    "        key_v3_3 = key.replace('.gru.', '.rnn.')\n",
    "        key_v3_3 = key_v3_3.replace('gru', 'recurrent_layer')\n",
    "        state_dict_v3_3[key_v3_3] = state_dict_v3_3.pop(key)\n",
    "        \n",
    "modelv3_3.load_state_dict(state_dict_v3_3)\n",
    "torch.save({\"state_dict\": modelv3_3.state_dict()}, RESULT_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35344f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
