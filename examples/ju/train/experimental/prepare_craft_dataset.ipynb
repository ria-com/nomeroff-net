{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a16011a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "\n",
    "import json\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import tqdm\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "from collections import Counter\n",
    "from torch.utils.data import DataLoader, random_split, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e7c8dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5270a4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nomeroff_net path\n",
    "NOMEROFF_NET_DIR = os.path.abspath('../')\n",
    "\n",
    "sys.path.append(NOMEROFF_NET_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a657b25e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights from checkpoint (/mnt/store/nomeroff-net/nomeroff_net/tools/../../data/./models/np_points_craft/craft_mlt/craft_mlt_25k_2020-02-16.pth)\n",
      "Loading weights of refiner from checkpoint (/mnt/store/nomeroff-net/nomeroff_net/tools/../../data/./models/np_points_craft/craft_refiner/craft_refiner_CTW1500_2020-02-16.pth)\n"
     ]
    }
   ],
   "source": [
    "from nomeroff_net.bbox_np_points import np_points_craft, get_cv_zone_rgb, convert_cv_zones_rgb_to_bgr, reshape_points\n",
    "np_points_craft = np_points_craft()\n",
    "np_points_craft.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a30d6625",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6039aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (10, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "411f6183",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_craft(json_path, img_path):\n",
    "    count = Counter()\n",
    "    with open(json_path) as json_file:\n",
    "        data = json.load(json_file)\n",
    "        for p in tqdm.tqdm(data['_via_img_metadata']):\n",
    "            item = data['_via_img_metadata'][p]\n",
    "            file_name = item[\"file_name\"]\n",
    "            image_path = os.path.join(img_path, file_name)\n",
    "            img = cv2.imread(image_path)\n",
    "            target_boxes = []\n",
    "            for region in item['regions']:\n",
    "                if len(region['shape_attributes'].get('all_points_x', [])) != 4:\n",
    "                    continue\n",
    "                if len(region['shape_attributes'].get('all_points_y', [])) != 4:\n",
    "                    continue\n",
    "                \n",
    "                xs = np.array(region['shape_attributes']['all_points_x'])\n",
    "                ys = np.array(region['shape_attributes']['all_points_y'])\n",
    "                min_x = min(xs)\n",
    "                max_x = max(xs)\n",
    "                min_y = min(ys)\n",
    "                max_y = max(ys)\n",
    "                target_boxes.append([min_x, min_y, max_x, max_y])\n",
    "            count[\"all\"] += len(target_boxes)\n",
    "            try:\n",
    "                all_points = np_points_craft.detect(img, target_boxes, [5, 2, 0])\n",
    "            except:\n",
    "                all_points = []\n",
    "            count[\"craft\"] += len(all_points)\n",
    "            #for points in all_points:\n",
    "            #    cv2.polylines(img, np.array([points], np.int32), True, (255, 0, 0), 3)\n",
    "            #plt.imshow(img)\n",
    "            #plt.show()\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de170b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_img_path=\"../datasets/autoriaNumberplateDataset-2021-05-12/val\"\n",
    "val_json_path=\"../datasets/autoriaNumberplateDataset-2021-05-12/val/via_region_data.json\"\n",
    "train_img_path=\"../datasets/autoriaNumberplateDataset-2021-05-12/train\"\n",
    "train_json_path=\"../datasets/autoriaNumberplateDataset-2021-05-12/train/via_region_data.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42b3b86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check_craft(val_json_path, val_img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d882047",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check_craft(train_json_path, train_img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92a6087",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83df0daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 36)\n",
    "\n",
    "        # Spatial transformer localization-network\n",
    "        self.localization = nn.Sequential(\n",
    "            nn.Conv2d(1, 8, kernel_size=7),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(8, 10, kernel_size=5),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "\n",
    "        # Regressor for the 3 * 2 affine matrix\n",
    "        self.fc_loc = nn.Sequential(\n",
    "            nn.Linear(10 * 3 * 3, 32),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(32, 3 * 2)\n",
    "        )\n",
    "\n",
    "        # Initialize the weights/bias with identity transformation\n",
    "        self.fc_loc[2].weight.data.zero_()\n",
    "        self.fc_loc[2].bias.data.copy_(torch.tensor([1, 0, 0, 0, 1, 0], dtype=torch.float))\n",
    "\n",
    "    # Spatial transformer network forward function\n",
    "    def stn(self, x):\n",
    "        xs = self.localization(x)\n",
    "        xs = xs.view(-1, 10 * 3 * 3)\n",
    "        theta = self.fc_loc(xs)\n",
    "        theta = theta.view(-1, 2, 3)\n",
    "\n",
    "        grid = F.affine_grid(theta, x.size())\n",
    "        x = F.grid_sample(x, grid)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        # transform the input\n",
    "        x = self.stn(x)\n",
    "\n",
    "        # Perform the usual forward pass\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "\n",
    "model = Net().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "14aa8734",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
       "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
       "  (fc2): Linear(in_features=50, out_features=36, bias=True)\n",
       "  (localization): Sequential(\n",
       "    (0): Conv2d(1, 8, kernel_size=(7, 7), stride=(1, 1))\n",
       "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Conv2d(8, 10, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): ReLU(inplace=True)\n",
       "  )\n",
       "  (fc_loc): Sequential(\n",
       "    (0): Linear(in_features=90, out_features=32, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Linear(in_features=32, out_features=6, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"letter_recognition.ph\"))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d9828473",
   "metadata": {},
   "outputs": [],
   "source": [
    "whitelist = [\n",
    "    letter for letter in \"ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "576c5724",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import copy\n",
    "import easyocr\n",
    "import torch\n",
    "from craft_mlt import imgproc\n",
    "from craft_mlt.craft import CRAFT\n",
    "from craft_mlt.refinenet import RefineNet\n",
    "from craft_mlt import craft_utils\n",
    "from typing import List, Dict, Tuple, Any, Union\n",
    "\n",
    "\n",
    "def get_det_boxes(textmap, linkmap, text_threshold, link_threshold, low_text):\n",
    "    # prepare data\n",
    "    linkmap = linkmap.copy()\n",
    "    textmap = textmap.copy()\n",
    "    img_h, img_w = textmap.shape\n",
    "\n",
    "    \"\"\" labeling method \"\"\"\n",
    "    ret, text_score = cv2.threshold(textmap, low_text, 1, 0)\n",
    "    ret, link_score = cv2.threshold(linkmap, link_threshold, 1, 0)\n",
    "\n",
    "    text_score_comb = np.clip(text_score + link_score, 0, 1)\n",
    "    nLabels, labels, stats, centroids = cv2.connectedComponentsWithStats(text_score_comb.astype(np.uint8),\n",
    "                                                                         connectivity=4)\n",
    "\n",
    "    det = []\n",
    "    mapper = []\n",
    "    for k in range(1, nLabels):\n",
    "        # size filtering\n",
    "        size = stats[k, cv2.CC_STAT_AREA]\n",
    "        if size < 10: continue\n",
    "\n",
    "        # thresholding\n",
    "        if np.max(textmap[labels == k]) < text_threshold: continue\n",
    "\n",
    "        # make segmentation map\n",
    "        segmap = np.zeros(textmap.shape, dtype=np.uint8)\n",
    "        segmap[labels == k] = 255\n",
    "        segmap[np.logical_and(link_score == 1, text_score == 0)] = 0  # remove link area\n",
    "        x, y = stats[k, cv2.CC_STAT_LEFT], stats[k, cv2.CC_STAT_TOP]\n",
    "        w, h = stats[k, cv2.CC_STAT_WIDTH], stats[k, cv2.CC_STAT_HEIGHT]\n",
    "        niter = int(math.sqrt(size * min(w, h) / (w * h)) * 2)\n",
    "        sx, ex, sy, ey = x - niter, x + w + niter + 1, y - niter, y + h + niter + 1\n",
    "        # boundary check\n",
    "        if sx < 0: sx = 0\n",
    "        if sy < 0: sy = 0\n",
    "        if ex >= img_w: ex = img_w\n",
    "        if ey >= img_h: ey = img_h\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1 + niter, 1 + niter))\n",
    "        segmap[sy:ey, sx:ex] = cv2.dilate(segmap[sy:ey, sx:ex], kernel)\n",
    "\n",
    "        # make box\n",
    "        np_contours = np.roll(np.array(np.where(segmap != 0)), 1, axis=0).transpose().reshape(-1, 2)\n",
    "        rectangle = cv2.minAreaRect(np_contours)\n",
    "        box = cv2.boxPoints(rectangle)\n",
    "\n",
    "        # align diamond-shape\n",
    "        w, h = np.linalg.norm(box[0] - box[1]), np.linalg.norm(box[1] - box[2])\n",
    "        box_ratio = max(w, h) / (min(w, h) + 1e-5)\n",
    "        if abs(1 - box_ratio) <= 0.1:\n",
    "            l, r = min(np_contours[:, 0]), max(np_contours[:, 0])\n",
    "            t, b = min(np_contours[:, 1]), max(np_contours[:, 1])\n",
    "            box = np.array([[l, t], [r, t], [r, b], [l, b]], dtype=np.float32)\n",
    "\n",
    "        # make clock-wise order\n",
    "        startidx = box.sum(axis=1).argmin()\n",
    "        box = np.roll(box, 4 - startidx, 0)\n",
    "        box = np.array(box)\n",
    "\n",
    "        det.append(box)\n",
    "        mapper.append(k)\n",
    "\n",
    "    return det\n",
    "\n",
    "@torch.no_grad()\n",
    "def test_net(image: np.ndarray, \n",
    "             net: CRAFT = np_points_craft.net, \n",
    "             text_threshold: float = 0.6,\n",
    "             link_threshold: float = 0.7, \n",
    "             low_text: float = 0.4, \n",
    "             cuda: bool = True,\n",
    "             poly: bool = False, \n",
    "             canvas_size: int = 300, \n",
    "             refine_net: RefineNet = np_points_craft.refine_net,\n",
    "             mag_ratio: float = 1.5) -> Tuple[Any, Any]:\n",
    "    \"\"\"\n",
    "    TODO: describe function\n",
    "    \"\"\"\n",
    "\n",
    "    # resize\n",
    "    img_resized, target_ratio, size_heatmap = imgproc.resize_aspect_ratio(image,\n",
    "                                                                          canvas_size,\n",
    "                                                                          interpolation=cv2.INTER_LINEAR,\n",
    "                                                                          mag_ratio=mag_ratio)\n",
    "    ratio_h = ratio_w = 1 / target_ratio\n",
    "\n",
    "    # preprocessing\n",
    "    x = imgproc.normalizeMeanVariance(img_resized)\n",
    "    x = torch.from_numpy(x).permute(2, 0, 1)  # [h, w, c] to [c, h, w]\n",
    "    x = Variable(x.unsqueeze(0))  # [c, h, w] to [b, c, h, w]\n",
    "    if cuda:\n",
    "        x = x.cuda()\n",
    "\n",
    "    # forward pass\n",
    "    y, feature = net(x)\n",
    "\n",
    "    # make score and link map\n",
    "    score_text = y[0, :, :, 0].cpu().data.numpy()\n",
    "    score_link = y[0, :, :, 1].cpu().data.numpy()\n",
    "\n",
    "    # refine link\n",
    "    if refine_net is not None:\n",
    "        y_refiner = refine_net(y, feature)\n",
    "        score_link = y_refiner[0, :, :, 0].cpu().data.numpy()\n",
    "\n",
    "    # Post-processing\n",
    "    boxes = get_det_boxes(score_text, score_link, text_threshold, link_threshold, low_text)\n",
    "\n",
    "    # coordinate adjustment\n",
    "    boxes = craft_utils.adjustResultCoordinates(boxes, ratio_w, ratio_h)\n",
    "\n",
    "    # render results (optional)\n",
    "    render_img = score_text.copy()\n",
    "    render_img = np.hstack((render_img, score_link))\n",
    "    ret_score_text = imgproc.cvt2HeatmapImg(render_img)\n",
    "    return boxes, ret_score_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "09218498",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_pading_to_bbox(bbox, dr = 0.2):\n",
    "    ## get the center and the radius\n",
    "    x, y, w, h = bbox\n",
    "\n",
    "    cx = x+w//2\n",
    "    cy = y+h//2\n",
    "    ch  = h/2\n",
    "    cw  = w/2\n",
    "\n",
    "    ## set offset, repeat enlarger ROI\n",
    "    rx = cw + cw*dr\n",
    "    ry = ch + ch*dr\n",
    "\n",
    "    new_bbox = [(int(cx-rx), int(cy-ry)), (int(cx+rx), int(cy+ry))]\n",
    "    return new_bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "de503630",
   "metadata": {},
   "outputs": [],
   "source": [
    "def polygon_to_bbox(polygon):\n",
    "    min_x = np.min(polygon[:, 0])\n",
    "    max_x = np.max(polygon[:, 0])\n",
    "    min_y = np.min(polygon[:, 1])\n",
    "    max_y = np.max(polygon[:, 1])\n",
    "    return (min_x, min_y, max_x-min_x, max_y-min_y)\n",
    "\n",
    "def polygons_to_bboxs(points, dr = 0.2):\n",
    "    bboxs = []\n",
    "    for polygon in polygons:\n",
    "        bbox = polygon_to_bbox(polygon)\n",
    "        bbox = add_pading_to_bbox(bbox, dr)\n",
    "        bboxs.append(bbox)\n",
    "    return bboxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "64f924fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_angle(vector_1, vector_2):\n",
    "    unit_vector_1 = vector_1 / np.linalg.norm(vector_1)\n",
    "    unit_vector_2 = vector_2 / np.linalg.norm(vector_2)\n",
    "    dot_product = np.dot(unit_vector_1, unit_vector_2)\n",
    "    angle = np.arccos(dot_product)\n",
    "    return math.degrees(angle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "9ee21b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from random import randint\n",
    "from math import sin, cos, radians\n",
    "\n",
    "\n",
    "def rotatePolygon(points, degrees_x, degrees_y):\n",
    "    \"\"\" Rotate polygon the given angle about its center. \"\"\"\n",
    "    theta_x = radians(degrees_x)  # Convert angle to radians\n",
    "    cosang_x, sinang_x = cos(theta_x), sin(theta_x)\n",
    "    \n",
    "    theta_y = radians(degrees_y) \n",
    "    cosang_y, sinang_y = cos(theta_y), sin(theta_y)\n",
    "\n",
    "    # find center point of Polygon to use as pivot\n",
    "    n = len(points)\n",
    "    cx = sum(p[0] for p in points) / n\n",
    "    cy = sum(p[1] for p in points) / n\n",
    "\n",
    "    new_points = []\n",
    "    for p in points:\n",
    "        x, y = p[0], p[1]\n",
    "        tx, ty = x-cx, y-cy\n",
    "        new_x = ( tx*cosang_x + ty*sinang_y) + cx\n",
    "        new_y = (-tx*sinang_x + ty*cosang_y) + cy\n",
    "        new_points.append([new_x, new_y])\n",
    "\n",
    "    return new_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "2b399fec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90.0"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_angle([0, 1], [1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "59a2e001",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_path = train_json_path\n",
    "img_path = train_img_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a87198c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "4677c88c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7666/7666 [04:41<00:00, 27.26it/s]\n"
     ]
    }
   ],
   "source": [
    "N = 10\n",
    "j = 0\n",
    "\n",
    "with open(json_path) as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "for p in tqdm.tqdm(data['_via_img_metadata']):\n",
    "    item = data['_via_img_metadata'][p]\n",
    "    file_name = item[\"file_name\"]\n",
    "    #print(file_name)\n",
    "    image_path = os.path.join(img_path, file_name)\n",
    "    img = cv2.imread(image_path)\n",
    "    letter_regions = []\n",
    "    for region in item['regions']:\n",
    "        if 'all_points_x' not in region['shape_attributes']:\n",
    "            continue\n",
    "        xs = np.array(region['shape_attributes']['all_points_x'])\n",
    "        ys = np.array(region['shape_attributes']['all_points_y'])\n",
    "        \n",
    "        angle_xs = []\n",
    "        angle_xs.append(find_angle([xs[-1], ys[-1]], [xs[0], ys[0]]))\n",
    "        angle_xs.append(find_angle([xs[1], ys[1]], [xs[2], ys[2]]))\n",
    "        angle_x = np.mean(angle_xs)\n",
    "        \n",
    "        angle_ys = []\n",
    "        angle_ys.append(find_angle([xs[0], ys[0]], [xs[1], ys[1]]))\n",
    "        angle_ys.append(find_angle([xs[2], ys[2]], [xs[3], ys[3]]))\n",
    "        angle_y = np.mean(angle_y)\n",
    "        \n",
    "        min_x = int(min(xs))\n",
    "        max_x = int(max(xs))\n",
    "        min_y = int(min(ys))\n",
    "        max_y = int(max(ys))\n",
    "        img_part = img[min_y:max_y, min_x:max_x]\n",
    "        if img_part.size == 0:\n",
    "            continue\n",
    "        canvas = copy.deepcopy(img_part)\n",
    "        polygons, ret_score_text = test_net(img_part, \n",
    "                                         refine_net=None, \n",
    "                                         #mag_ratio=1,\n",
    "                                         low_text=0.6)\n",
    "        bboxs = polygons_to_bboxs(polygons, 0.3)\n",
    "        \n",
    "        for i, bbox in enumerate(bboxs):\n",
    "            letter_img = img_part[bbox[0][1]:bbox[1][1], bbox[0][0]:bbox[1][0]]\n",
    "            if letter_img.size == 0:\n",
    "                continue\n",
    "            letter_img_rgb = cv2.cvtColor(letter_img, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            x = cv2.resize(letter_img_rgb, (28, 28))\n",
    "            x = cv2.cvtColor(x, cv2.COLOR_RGB2GRAY)\n",
    "            x = cv2.normalize(x, None, alpha=0, beta=1,\n",
    "                                norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "            x = x.reshape((*x.shape, 1))\n",
    "            x = np.moveaxis(np.array(x), 2, 0)\n",
    "            x = x.reshape((1, *x.shape))\n",
    "            x = torch.from_numpy(x)\n",
    "            x = x.to(device)\n",
    "            \n",
    "            y = model(x)\n",
    "            y = y.cpu().detach().numpy()[0]\n",
    "            text = whitelist[np.argmax(y)]\n",
    "            \n",
    "            pts = list(zip([bbox[1][0], bbox[1][0], bbox[0][0], bbox[0][0]],\n",
    "                           [bbox[0][1], bbox[1][1], bbox[1][1], bbox[0][1]]))\n",
    "            #pts = np.array(pts, np.int32)\n",
    "            #img_part = cv2.polylines(img_part, [pts], True, (0, 255, 0), 2)\n",
    "            pts = rotatePolygon(pts, -angle_x, 0)\n",
    "            pts = rotatePolygon(pts, 0, -angle_y)\n",
    "            pts = np.array(pts, np.int32)\n",
    "            letter_regions.append({\n",
    "                'region_attributes': {\n",
    "                    'class': text\n",
    "                }, \n",
    "                'shape_attributes': {\n",
    "                    'name': 'polygon', \n",
    "                    'all_points_x': [p[0]+min_x for p in pts.tolist()],\n",
    "                    'all_points_y': [p[1]+min_y for p in pts.tolist()],\n",
    "                }\n",
    "            })\n",
    "            \n",
    "            #img_part = cv2.polylines(img_part, [pts], True, (255, 0, 0), 2)\n",
    "            \n",
    "        #plt.imshow(img_part)\n",
    "        #plt.show()\n",
    "    data['_via_img_metadata'][p]['regions'] = letter_regions\n",
    "#     j += 1\n",
    "#     if j >= N:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "4ebb3ae3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with open(f\"{'.'.join(json_path.split('.')[:-1])}_letters_bbox.json\", \"w\") as json_file:\n",
    "    json.dump(data, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a28abcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae110fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (python3.9)",
   "language": "python",
   "name": "python3.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
