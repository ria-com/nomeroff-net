{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This example demonstrate how to train YOLO detector model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "import yaml\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# change this property\n",
    "NOMEROFF_NET_DIR = os.path.abspath('../../../../')\n",
    "sys.path.append(NOMEROFF_NET_DIR)\n",
    "\n",
    "from nomeroff_net.tools.yolo_tools import convert_dataset_to_yolo_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (20, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download dataset and yolo repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# auto download latest dataset\n",
    "from nomeroff_net.tools import modelhub\n",
    "\n",
    "# get yolov5\n",
    "info = modelhub.download_repo_for_model(\"yolov5\")\n",
    "repo_path = info[\"repo_path\"]\n",
    "\n",
    "# # auto download latest dataset\n",
    "# info = modelhub.download_dataset_for_model(\"yolov5\")\n",
    "# PATH_TO_DATASET = info[\"dataset_path\"]\n",
    "\n",
    "# local path dataset\n",
    "PATH_TO_DATASET = os.path.join(NOMEROFF_NET_DIR, \"./data/dataset/Detector/autoria_numberplate_dataset_example\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert dataset to yolo format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES = ['numberplate']\n",
    "STATES  = [\"val\",\"train\"]\n",
    "#STATES  = [\"val\"]\n",
    "\n",
    "PATH_TO_RES_ANN = os.path.join(os.path.dirname(PATH_TO_DATASET), \"./npdata/labels/{}\")\n",
    "PATH_TO_RES_IMAGES  = os.path.join(os.path.dirname(PATH_TO_DATASET), \"./npdata/images/{}\")\n",
    "\n",
    "PATH_TO_JSON = os.path.join(PATH_TO_DATASET, \"{}/via_region_data.json\")\n",
    "PATH_TO_IMAGES = os.path.join(PATH_TO_DATASET, \"{}/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] val data creating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.63it/s]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] train data creating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.57it/s]\n"
     ]
    }
   ],
   "source": [
    "EXIST_STRATEGY = \"exist_ok\" # \"delete\", \"exist_ok\"\n",
    "\n",
    "for state in STATES:\n",
    "    path_to_res_ann    = PATH_TO_RES_ANN.format(state)\n",
    "    path_to_res_images = PATH_TO_RES_IMAGES.format(state)\n",
    "    \n",
    "    if os.path.exists(path_to_res_ann) and os.path.exists(path_to_res_images) and EXIST_STRATEGY == \"exist_ok\":\n",
    "        print(\"[INFO]\", state, \"data exists\")\n",
    "        continue\n",
    "    if EXIST_STRATEGY == \"delete\":\n",
    "        shutil.rmtree(path_to_res_ann)\n",
    "        shutil.rmtree(path_to_res_images)\n",
    "    \n",
    "    print(\"[INFO]\", state, \"data creating...\")\n",
    "    os.makedirs(path_to_res_ann, exist_ok=True)\n",
    "    os.makedirs(path_to_res_images, exist_ok=True)\n",
    "    \n",
    "    path_to_json    = PATH_TO_JSON.format(state)\n",
    "    path_to_images  = PATH_TO_IMAGES.format(state)\n",
    "    \n",
    "    convert_dataset_to_yolo_format(\n",
    "        path_to_res_ann, \n",
    "        path_to_res_images,\n",
    "        path_to_images, \n",
    "        path_to_json, \n",
    "        debug=False,\n",
    "        is_generate_image_rotation_variants=True\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create yaml config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] config: {'path': '/mnt/data/var/www/nomeroff-net/./data/dataset/Detector', 'train': './npdata/images/train', 'val': './npdata/images/val', 'nc': 1, 'names': ['numberplate']}\n",
      "[INFO] config saved into /mnt/data/var/www/nomeroff-net/./data/dataset/Detector/./npdata/numberplate_config.yaml\n"
     ]
    }
   ],
   "source": [
    "yaml_path = os.path.join(os.path.dirname(PATH_TO_DATASET), \"./npdata/numberplate_config.yaml\")\n",
    "yaml_dataset_config = {\n",
    "    # Train/val/test sets\n",
    "    \"path\": os.path.dirname(PATH_TO_DATASET), \n",
    "    \"train\": \"./npdata/images/train\",\n",
    "    \"val\": \"./npdata/images/val\",\n",
    "    #\"test\": \"\" # test images (optional)\n",
    "    \n",
    "    # Classes\n",
    "    \"nc\": 1,  # number of classes\n",
    "    \"names\": [ \"numberplate\" ]  # class names\n",
    "}\n",
    "print(\"[INFO] config:\", yaml_dataset_config)\n",
    "print(\"[INFO] config saved into\", yaml_path)\n",
    "with open(yaml_path, 'w') as yaml_file:\n",
    "    yaml.dump(yaml_dataset_config, \n",
    "              yaml_file, \n",
    "              default_flow_style=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLI yolo training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: wandb: command not found\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=/mnt/data/var/www/nomeroff-net/./data/dataset/Detector/./npdata/numberplate_config.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=5, batch_size=1, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0mâš ï¸ YOLOv5 is out of date by 3 commits. Use `git pull` or `git clone https://github.com/ultralytics/yolov5` to update.\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m tensorboard>=2.4.1 not found and is required by YOLOv5, attempting auto-update...\n",
      "\u001b[31mERROR: Could not install packages due to an EnvironmentError: [Errno 13] Permission denied: '/usr/local/lib/python3.8/site-packages/tensorboard_data_server-0.6.1.dist-info'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\u001b[0m\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m Command 'pip install 'tensorboard>=2.4.1'' returned non-zero exit status 1.\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m pandas>=1.1.4 not found and is required by YOLOv5, attempting auto-update...\n",
      "\u001b[31mERROR: flask-appbuilder 3.3.2 has requirement Flask<2,>=0.12, but you'll have flask 2.0.2 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: flask-appbuilder 3.3.2 has requirement SQLAlchemy<1.4.0, but you'll have sqlalchemy 1.4.17 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: boto3 1.15.2 has requirement botocore<1.19.0,>=1.18.2, but you'll have botocore 1.23.24 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: apache-airflow 2.1.3 has requirement flask<2.0,>=1.1.0, but you'll have flask 2.0.2 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: apache-airflow 2.1.3 has requirement importlib-resources~=1.4, but you'll have importlib-resources 5.4.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: apache-airflow 2.1.3 has requirement itsdangerous<2.0,>=1.1.0, but you'll have itsdangerous 2.0.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: apache-airflow 2.1.3 has requirement markupsafe<2.0,>=1.1.1, but you'll have markupsafe 2.0.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: apache-airflow 2.1.3 has requirement werkzeug>=1.0.1,~=1.0, but you'll have werkzeug 2.0.2 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: Could not install packages due to an EnvironmentError: [Errno 13] Permission denied: '/usr/local/lib/python3.8/site-packages/python_dateutil-2.8.2.dist-info'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\u001b[0m\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m Command 'pip install 'pandas>=1.1.4'' returned non-zero exit status 1.\n",
      "YOLOv5 ðŸš€ v6.1-62-ga0a4adf torch 1.9.0+cu102 CPU\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mWeights & Biases: \u001b[0mrun 'pip install wandb' to automatically track and visualize YOLOv5 ðŸš€ runs (RECOMMENDED)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
      "2022-03-26 11:13:04.767777: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib64/python3.8/site-packages/cv2/../../lib64:/usr/local/lib64/python3.8/site-packages/cv2/../../lib64:\n",
      "2022-03-26 11:13:04.767799: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "Downloading https://github.com/ultralytics/yolov5/releases/download/v6.1/yolov5s.pt to yolov5s.pt...\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14.1M/14.1M [01:42<00:00, 144kB/s]\n",
      "\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     16182  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
      "Model summary: 270 layers, 7022326 parameters, 7022326 gradients\n",
      "\n",
      "Transferred 343/349 items from yolov5s.pt\n",
      "Scaled weight_decay = 0.0005\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 57 weight (no decay), 60 weight, 60 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/mnt/data/var/www/nomeroff-net/data/dataset/Detector/npdata/lab\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /mnt/data/var/www/nomeroff-net/data/dataset/Detector/npdata/labels/train.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/mnt/data/var/www/nomeroff-net/data/dataset/Detector/npdata/label\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /mnt/data/var/www/nomeroff-net/data/dataset/Detector/npdata/labels/val.cache\n",
      "Plotting labels to runs/train/exp/labels.jpg... \n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m5.75 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset âœ…\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns/train/exp\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       0/4        0G   0.09593   0.03335         0         0       640: 100%|â–ˆâ–ˆâ–ˆ\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all          4          4    0.00213       0.25   0.000873   0.000262\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       1/4        0G    0.1017   0.03275         0         1       640: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all          4          4    0.00191       0.25   0.000797   0.000159\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       2/4        0G   0.07974   0.03417         0         1       640: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all          4          4    0.00191       0.25   0.000797   0.000159\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       3/4        0G    0.1013   0.03034         0         1       640: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all          4          4    0.00191       0.25   0.000797   0.000159\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       4/4        0G   0.05133   0.02731         0         0       640: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all          4          4    0.00191       0.25   0.000797   0.000159\n",
      "\n",
      "5 epochs completed in 0.008 hours.\n",
      "Optimizer stripped from runs/train/exp/weights/last.pt, 14.4MB\n",
      "Optimizer stripped from runs/train/exp/weights/best.pt, 14.4MB\n",
      "\n",
      "Validating runs/train/exp/weights/best.pt...\n",
      "Fusing layers... \n",
      "Model summary: 213 layers, 7012822 parameters, 0 gradients\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all          4          4    0.00213       0.25    0.00088   0.000264\n",
      "Results saved to \u001b[1mruns/train/exp\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!cd {repo_path}; \\\n",
    " wandb offline; \\\n",
    " python3 train.py \\\n",
    "    --img 640 \\\n",
    "    --batch 1 \\\n",
    "    --epochs 1 \\\n",
    "    --data {yaml_path} \\\n",
    "    --weights yolov5s.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/data/var/www/nomeroff-net/nomeroff_net/tools/../../data/./repos/Detector/yolov5'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repo_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run wandb localy\n",
    "\n",
    "```\n",
    "docker run --rm -it -v wandb:{repo_path}/wandb -p 8080:8080 --ip 0.0.0.0 --name wandb-local wandb/local\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
