{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4bab52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import glob\n",
    "import cv2\n",
    "import json\n",
    "import string\n",
    "import tqdm\n",
    "import numpy as np\n",
    "from imutils.perspective import four_point_transform\n",
    "from skimage import exposure\n",
    "\n",
    "from skimage.io import imread, imshow\n",
    "from skimage import img_as_ubyte\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.exposure import histogram, cumulative_distribution\n",
    "from scipy.stats import cauchy, logistic\n",
    "\n",
    "import imutils\n",
    "from PIL import ImageFont, ImageDraw, Image\n",
    "from matplotlib import pyplot as plt\n",
    "from _paths import nomeroff_net_dir\n",
    "from nomeroff_net.tools import modelhub\n",
    "from collections import Counter\n",
    "import re\n",
    "import string\n",
    "\n",
    "import albumentations as A\n",
    "from nomeroff_net.tools.image_processing import get_cv_zone_rgb, distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2b55bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(image):\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b2e925b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (20,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6320e571",
   "metadata": {},
   "outputs": [],
   "source": [
    "info = modelhub.download_repo_for_model(\"yolov5\")\n",
    "repo_path = info[\"repo_path\"]\n",
    "\n",
    "# auto download latest dataset\n",
    "info = modelhub.download_dataset_for_model(\"yolov5\")\n",
    "PATH_TO_DATASET = info[\"dataset_path\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1dddf59",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = PATH_TO_DATASET\n",
    "dataset = \"train\"\n",
    "json_data_path = \"train/via_region_data.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4bdbe582",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_formats = {\n",
    "    \"@####@@\": \"kg-1995.png\",\n",
    "    \"@####@\": \"kg-1995.png\",\n",
    "    \"#####@@@\": \"kg-2015.png\",\n",
    "}\n",
    "path_to_images_example = os.path.join(nomeroff_net_dir, \n",
    "                                      \"data/dataset/OptionsDetector/numberplate_options_example/train/img/{}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed265a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FONT\n",
    "fontpath = os.path.join(nomeroff_net_dir, \"data/font/186-font.otf\")\n",
    "font = ImageFont.truetype(fontpath, 43)\n",
    "number_fontpath = os.path.join(nomeroff_net_dir, \"data/font/3827-font.otf\")\n",
    "number_font = ImageFont.truetype(number_fontpath, 48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0bf5c154",
   "metadata": {},
   "outputs": [],
   "source": [
    "avaliable_letters = [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\", \"J\", \"K\", \"L\", \"M\", \n",
    "                     \"N\", \"O\", \"P\", \"Q\", \"R\", \"S\", \"T\", \"U\", \"V\", \"W\", \"X\", \"Y\", \"Z\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9392349",
   "metadata": {},
   "source": [
    "# READ DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4a72f44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8411/8411 [00:00<00:00, 284529.88it/s]\n"
     ]
    }
   ],
   "source": [
    "res_datasets = {}\n",
    "res_datasets[dataset] = []\n",
    "\n",
    "with open(os.path.join(ROOT_DIR, json_data_path)) as jsonFile:\n",
    "    json_data = json.load(jsonFile)\n",
    "for key in tqdm.tqdm((json_data[\"_via_img_metadata\"])):\n",
    "    metadata = json_data[\"_via_img_metadata\"][key]\n",
    "\n",
    "    # define image_id\n",
    "    image_file_name = metadata[\"filename\"]\n",
    "    image_file_name = os.path.join(ROOT_DIR, dataset, image_file_name)\n",
    "    for region in metadata[\"regions\"]:\n",
    "        if region[\"shape_attributes\"].get(\"all_points_x\", None) is None or region[\"shape_attributes\"].get(\"all_points_y\", None) is None:\n",
    "            continue\n",
    "        np_zone = [(x, y) for x, y in zip(region[\"shape_attributes\"][\"all_points_x\"], region[\"shape_attributes\"][\"all_points_y\"])]\n",
    "        res_datasets[dataset].append([image_file_name, np_zone])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77748b19",
   "metadata": {},
   "source": [
    "# TOOLS FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a9e4489",
   "metadata": {},
   "outputs": [],
   "source": [
    "def order_points(pts):\n",
    "    # initialzie a list of coordinates that will be ordered\n",
    "    # such that the first entry in the list is the top-left,\n",
    "    # the second entry is the top-right, the third is the\n",
    "    # bottom-right, and the fourth is the bottom-left\n",
    "    rect = np.zeros((4, 2), dtype = \"float32\")\n",
    "    # the top-left point will have the smallest sum, whereas\n",
    "    # the bottom-right point will have the largest sum\n",
    "    s = pts.sum(axis = 1)\n",
    "    rect[0] = pts[np.argmin(s)]\n",
    "    rect[2] = pts[np.argmax(s)]\n",
    "    # now, compute the difference between the points, the\n",
    "    # top-right point will have the smallest difference,\n",
    "    # whereas the bottom-left will have the largest difference\n",
    "    diff = np.diff(pts, axis = 1)\n",
    "    rect[1] = pts[np.argmin(diff)]\n",
    "    rect[3] = pts[np.argmax(diff)]\n",
    "    # return the ordered coordinates\n",
    "    return rect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ab115d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_linear_cdf(image, channel, name, ax):\n",
    "    image_intensity = img_as_ubyte(image[:,:,channel])\n",
    "    freq, bins = cumulative_distribution(image_intensity)\n",
    "    target_bins = np.arange(255)\n",
    "    target_freq = np.linspace(0, 1, len(target_bins))\n",
    "    ax.step(bins, freq, c='b', label='Actual CDF')\n",
    "    ax.plot(target_bins, target_freq, c='r', label='Target CDF')\n",
    "    ax.legend()\n",
    "    ax.set_title('{} Channel: Actual vs. '\n",
    "                 'Target Cumulative Distribution'.format(name))\n",
    "\n",
    "def linear_distribution(image, channel):\n",
    "    image_intensity = img_as_ubyte(image[:,:,channel])\n",
    "    freq, bins = cumulative_distribution(image_intensity)\n",
    "    target_bins = np.arange(255)\n",
    "    target_freq = np.linspace(0, 1, len(target_bins))\n",
    "    new_vals = np.interp(freq, target_freq, target_bins)\n",
    "    return new_vals[image_intensity].astype(np.uint8)\n",
    "\n",
    "\n",
    "def individual_channel(image, dist, channel):\n",
    "    im_channel = img_as_ubyte(image[:,:,channel])\n",
    "    freq, bins = cumulative_distribution(im_channel)\n",
    "    new_vals = np.interp(freq, dist.cdf(np.arange(0,256)), \n",
    "                               np.arange(0,256))\n",
    "    return new_vals[im_channel].astype(np.uint8)\n",
    "\n",
    "\n",
    "def distribution(image, function, mean, std):\n",
    "    dist = function(mean, std)\n",
    "    image_intensity = img_as_ubyte(rgb2gray(image))\n",
    "    freq, bins = cumulative_distribution(image_intensity)\n",
    "    red = individual_channel(image, dist, 0)\n",
    "    green = individual_channel(image, dist, 1)\n",
    "    blue = individual_channel(image, dist, 2)\n",
    "    corrected_image = np.dstack((red, green, blue))\n",
    "    return corrected_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c67f4d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_img():\n",
    "    random_i = random.randint(0, len(res_datasets[dataset]) - 1)\n",
    "    fake_img_path, fake_np_four_points = res_datasets[dataset][random_i]\n",
    "\n",
    "    fake_img = cv2.imread(fake_img_path)[:,:,::-1]\n",
    "    fake_img = np.concatenate((fake_img, 255*np.ones((*fake_img.shape[:2], 1))), axis=2)\n",
    "    ordered_p_fake = order_points(np.array(fake_np_four_points, dtype = \"float32\"))\n",
    "\n",
    "    return fake_img, ordered_p_fake\n",
    "\n",
    "\n",
    "def draw_fake(img, fake_img, ordered_p_fake):\n",
    "    ordered_p_orig = np.array([(0, 0), \n",
    "                               (img.shape[1], 0), \n",
    "                               (img.shape[1], img.shape[0]), \n",
    "                               (0, img.shape[0])], dtype = \"float32\")\n",
    "    \n",
    "\n",
    "    M = cv2.getPerspectiveTransform(ordered_p_orig, \n",
    "                                    ordered_p_fake)\n",
    "    warped = cv2.warpPerspective(img, M, (fake_img.shape[1], fake_img.shape[0]))\n",
    "    cntrs = ordered_p_fake.reshape(1, ordered_p_fake.shape[0], ordered_p_fake.shape[1]).astype(np.int32)\n",
    "\n",
    "    stencil = np.zeros(warped.shape).astype(warped.dtype)\n",
    "    contours = cntrs\n",
    "    \n",
    "    cv2.fillPoly(stencil, contours, [255, 255, 255])\n",
    "    np_mask = cv2.bitwise_and(warped, stencil)\n",
    "    \n",
    "    overlay_img1 = np.ones(fake_img.shape, np.uint8)*255\n",
    "    \n",
    "    rows, cols, channels = np_mask.shape\n",
    "    overlay_img1[:, :] = warped\n",
    "    img2gray = cv2.cvtColor(overlay_img1, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    ret, mask = cv2.threshold(img2gray, 1, 255, cv2.THRESH_BINARY)\n",
    "        \n",
    "    mask_inv = cv2.bitwise_not(mask)\n",
    "\n",
    "    fake_img = fake_img.astype(np.uint8)\n",
    "    temp1 = cv2.bitwise_and(fake_img, fake_img, mask = mask_inv)\n",
    "    temp2 = cv2.bitwise_and(overlay_img1, overlay_img1, mask = mask)\n",
    "    \n",
    "    temp1 = temp1.astype(np.uint8)\n",
    "    fake_np_img = cv2.add(temp1, temp2)\n",
    "    return fake_np_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "023003bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def domain_adoptation(src, trg, freq):\n",
    "\n",
    "    \"\"\"\n",
    "    Parameters: \n",
    "    src - source image, which style has to be changed\n",
    "    trg - target image, which low-frequency domain will be adopted\n",
    "    freq - number of frequencies to be used\n",
    "\n",
    "    Returns:\n",
    "    result - np.array based on srs image (shape and high frequencies) \n",
    "         with low frequencies of the target image\n",
    "    \"\"\"\n",
    "\n",
    "    result = np.zeros((src.shape[0],src.shape[1],src.shape[2]))\n",
    "\n",
    "    for i in range(src.shape[2]):\n",
    "        trg_fft = np.fft.fft2(trg[:,:,i])\n",
    "        src_fft = np.fft.fft2(src[:,:,i])\n",
    "\n",
    "        trg_fft_shift = np.fft.fftshift(trg_fft)\n",
    "        src_fft_shift = np.fft.fftshift(src_fft)\n",
    "\n",
    "        src_fft_shift[src.shape[0]//2-freq:src.shape[0]//2+freq,\n",
    "                         src.shape[1]//2-freq:src.shape[1]//2+freq] = \\\n",
    "            trg_fft_shift[trg.shape[0]//2-freq:trg.shape[0]//2+freq,\n",
    "                           trg.shape[1]//2-freq:trg.shape[1]//2+freq]\n",
    "\n",
    "        src_ifft_shift = np.fft.ifftshift(src_fft_shift)\n",
    "\n",
    "        result[:,:,i] = np.fft.ifft2(src_ifft_shift)\n",
    "        result[:,:,i] = np.abs(result[:,:,i])\n",
    "\n",
    "    result = np.float32(result)\n",
    "    result = cv2.cvtColor(result, cv2.COLOR_BGR2RGB)\n",
    "    result = cv2.normalize(result,None,0,1,cv2.NORM_MINMAX)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c3bf02b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_transfer(source, target):\n",
    "    source = cv2.resize(source, (target.shape[1], target.shape[0]))\n",
    "    # convert the images from the RGB to L*ab* color space, being\n",
    "    # sure to utilizing the floating point data type (note: OpenCV\n",
    "    # expects floats to be 32-bit, so use that instead of 64-bit)\n",
    "    source = cv2.cvtColor(source, cv2.COLOR_BGR2LAB).astype(\"float32\")\n",
    "    target = cv2.cvtColor(target, cv2.COLOR_BGR2LAB).astype(\"float32\")\n",
    "    # compute color statistics for the source and target images\n",
    "    (lMeanSrc, lStdSrc, aMeanSrc, aStdSrc, bMeanSrc, bStdSrc) = image_stats(source)\n",
    "    (lMeanTar, lStdTar, aMeanTar, aStdTar, bMeanTar, bStdTar) = image_stats(target)\n",
    "    # subtract the means from the target image\n",
    "    (l, a, b) = cv2.split(target)\n",
    "    l -= lMeanTar\n",
    "    a -= aMeanTar\n",
    "    b -= bMeanTar\n",
    "    # scale by the standard deviations\n",
    "    l = (lStdTar / lStdSrc) * l\n",
    "    a = (aStdTar / aStdSrc) * a\n",
    "    b = (bStdTar / bStdSrc) * b\n",
    "    # add in the source mean\n",
    "    l += lMeanSrc\n",
    "    a += aMeanSrc\n",
    "    b += bMeanSrc\n",
    "    # clip the pixel intensities to [0, 255] if they fall outside\n",
    "    # this range\n",
    "    l = np.clip(l, 0, 255)\n",
    "    a = np.clip(a, 0, 255)\n",
    "    b = np.clip(b, 0, 255)\n",
    "    # merge the channels together and convert back to the RGB color\n",
    "    # space, being sure to utilize the 8-bit unsigned integer data\n",
    "    # type\n",
    "    transfer = cv2.merge([l, a, b])\n",
    "    transfer = cv2.cvtColor(transfer.astype(\"uint8\"), cv2.COLOR_LAB2BGR)\n",
    "\n",
    "    # return the color transferred image\n",
    "    return transfer\n",
    "\n",
    "\n",
    "def image_stats(image):\n",
    "    # compute the mean and standard deviation of each channel\n",
    "    (l, a, b) = cv2.split(image)\n",
    "    (lMean, lStd) = (l.mean(), l.std())\n",
    "    (aMean, aStd) = (a.mean(), a.std())\n",
    "    (bMean, bStd) = (b.mean(), b.std())\n",
    "    # return the color statistics\n",
    "    return (lMean, lStd, aMean, aStd, bMean, bStd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "10b13d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "BOX_COLOR = (255, 0, 0) # Red\n",
    "TEXT_COLOR = (255, 255, 255) # White\n",
    "\n",
    "\n",
    "def visualize_bbox(img, bbox, color=BOX_COLOR, thickness=2, **kwargs):\n",
    "    x_min, y_min, w, h = bbox\n",
    "    x_min, x_max, y_min, y_max = int(x_min), int(x_min + w), int(y_min), int(y_min + h)\n",
    "    cv2.rectangle(img, (x_min, y_min), (x_max, y_max), color=color, thickness=thickness)\n",
    "    return img\n",
    "\n",
    "def visualize_titles(img, bbox, title, color=BOX_COLOR, thickness=2, font_thickness = 2, font_scale=0.35, **kwargs):\n",
    "    x_min, y_min, w, h = bbox\n",
    "    x_min, x_max, y_min, y_max = int(x_min), int(x_min + w), int(y_min), int(y_min + h)\n",
    "    ((text_width, text_height), _) = cv2.getTextSize(title, cv2.FONT_HERSHEY_SIMPLEX, font_scale, font_thickness)\n",
    "    cv2.rectangle(img, (x_min, y_min - int(1.3 * text_height)), (x_min + text_width, y_min), BOX_COLOR, -1)\n",
    "    cv2.putText(img, title, (x_min, y_min - int(0.3 * text_height)), cv2.FONT_HERSHEY_SIMPLEX, font_scale, TEXT_COLOR,\n",
    "                font_thickness, lineType=cv2.LINE_AA)\n",
    "    return img\n",
    "\n",
    "\n",
    "def augment_and_show(aug, image, filename=None, \n",
    "                     font_scale_orig=0.35, font_scale_aug=0.35, show=True, **kwargs):\n",
    "\n",
    "    augmented = aug(image=image)\n",
    "\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image_aug = cv2.cvtColor(augmented['image'], cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    if show:\n",
    "        f, ax = plt.subplots(1, 2, figsize=(16, 8))\n",
    "        ax[0].imshow(image)\n",
    "        ax[0].set_title('Original image')\n",
    "        ax[1].imshow(image_aug)\n",
    "        ax[1].set_title('Augmented image')\n",
    "        f.tight_layout()\n",
    "\n",
    "        if filename is not None:\n",
    "            f.savefig(filename)\n",
    "        \n",
    "    return augmented['image']\n",
    "\n",
    "def find_in_dir(dirname):\n",
    "    return [os.path.join(dirname, fname) for fname in sorted(os.listdir(dirname))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bb78dac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_and_aug_numbeplate(np_img, ordered_p_fake):\n",
    "    l = np.random.uniform(0.01, 0.06)\n",
    "    random_r_crop = np.random.uniform(0.06, 0.1)\n",
    "    random_l_crop = np.random.uniform(0.01, 0.08)\n",
    "    np_img = np_img[:,:,:3].astype(np.uint8)\n",
    "    #print(np_img.shape)\n",
    "    # img_np = cv2.polylines(np_img, [ordered_p_fake.reshape((-1, 1, 2)).astype(np.int32)], True, (255, 0, 255), 2)\n",
    "    \n",
    "    d_crop_l = (distance(ordered_p_fake[0], ordered_p_fake[1])+distance(ordered_p_fake[3], ordered_p_fake[3]))/2*random_l_crop\n",
    "    d_crop_r = (distance(ordered_p_fake[0], ordered_p_fake[1])+distance(ordered_p_fake[3], ordered_p_fake[3]))/2*random_r_crop\n",
    "    d2 = (distance(ordered_p_fake[1], ordered_p_fake[2])+distance(ordered_p_fake[3], ordered_p_fake[0]))/2*l\n",
    "    ordered_p_fake[0,0] += d_crop_l\n",
    "    ordered_p_fake[1,0] -= d_crop_r\n",
    "    ordered_p_fake[2,0] -= d_crop_r\n",
    "    ordered_p_fake[3,0] += d_crop_l\n",
    "    \n",
    "    ordered_p_fake[1,1] -= d2\n",
    "    ordered_p_fake[2,1] += d2\n",
    "    ordered_p_fake[0,1] -= d2\n",
    "    ordered_p_fake[3,1] += d2\n",
    "    img_np = get_cv_zone_rgb(np_img, ordered_p_fake)\n",
    "    \n",
    "    light = A.Compose([\n",
    "        A.RandomBrightnessContrast(p=1),    \n",
    "        A.RandomGamma(p=1),    \n",
    "        A.CLAHE(p=1),\n",
    "        A.Blur(),\n",
    "        A.GaussNoise(),\n",
    "        A.ShiftScaleRotate(shift_limit=0.01, scale_limit=0.01, rotate_limit=2, p=.75),\n",
    "    ], p=5)\n",
    "\n",
    "    \n",
    "    # img_np = cv2.polylines(np_img, [ordered_p_fake.reshape((-1, 1, 2)).astype(np.int32)], True, (0, 255, 255), 2)\n",
    "    return augment_and_show(light, img_np, show=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5e3b3199",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_fake_numberplate(img, \n",
    "                          b: int = 20, g: int = 56, r: int = 0, a: int = 255,\n",
    "                          draw_text=True,\n",
    "                          draw_numbers=True,\n",
    "                          text_color=\"#000000\"):\n",
    "    img = img.copy()\n",
    "    img.thumbnail((235, 51))\n",
    "    \n",
    "    poly_w = 0\n",
    "    while poly_w < 100:\n",
    "        random_img, ordered_p_fake = get_random_img()\n",
    "        poly_w = distance(ordered_p_fake[0], ordered_p_fake[1])\n",
    "    \n",
    "    random_img = random_img.astype(np.uint8)\n",
    "    \n",
    "    #print(ordered_p_fake)\n",
    "    random_img_np = get_cv_zone_rgb(random_img, ordered_p_fake)\n",
    "#     print(\"random_img_np\", np.mean(random_img_np[:,:,:3]), np.max(random_img_np[:,:,:3]), \n",
    "#           np.min(random_img_np[:,:,:3]))\n",
    "#     plt.imshow(random_img_np)\n",
    "#     plt.show()\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    \n",
    "    numberpalte = random.choice(text_np_variants)\n",
    "    numberpalte = numberpalte[:2] + \"\".join(random.choices(string.digits, k=4)) \\\n",
    "                                       + numberpalte[-2:]\n",
    "    x_left_margin = 6\n",
    "    x_s = 27 + ((200 - (draw.textsize(numberpalte[:2], font)[0] + x_left_margin\n",
    "                     + draw.textsize(numberpalte[2:6], number_font)[0] + x_left_margin\n",
    "                     + draw.textsize(numberpalte[6:], font)[0])))/2\n",
    "    \n",
    "    #print(\"x_s\", x_s)\n",
    "    draw.rectangle([(28, 5), (226, 42)], fill =\"white\", outline =\"white\")\n",
    "    if draw_text:\n",
    "        draw.text((x_s, 8), numberpalte[:2], font = font, fill = (b, g, r, a))\n",
    "        x_s += draw.textsize(numberpalte[:2], font)[0] + x_left_margin\n",
    "    if draw_numbers:\n",
    "        draw.text((x_s, 4), numberpalte[2:6], font = number_font, fill = (b, g, r, a))\n",
    "        x_s += draw.textsize(numberpalte[2:6], number_font)[0] + x_left_margin\n",
    "    else:\n",
    "        x_s = 175.5\n",
    "    if draw_text:\n",
    "        draw.text((x_s, 8), numberpalte[6:], font = font, fill = (b, g, r, a))\n",
    "    \n",
    "    img = np.array(img)\n",
    "#     print(\"orig color\", np.mean(img[:,:,:3]), np.max(img[:,:,:3]), np.min(img[:,:,:3]))\n",
    "#     plt.imshow(img)\n",
    "#     plt.show()\n",
    "    \n",
    "    img[:,:,:3] = color_transfer(random_img_np, img[:,:,:3])\n",
    "    # \"speckle\", \"poisson\", \"s&p\",  \"gauss\"\n",
    "    #img[:,:,:3] = noisy(\"gauss\", img[:,:,:3])\n",
    "    #img[:,:,:3] = domain_adoptation(src=img[:,:,:3], trg=random_img_np, freq=1)\n",
    "    #img[:,:,:3] = distribution(img[:,:,:3], cauchy,  np.mean(random_img), np.mean(random_img)+90)\n",
    "    \n",
    "#     print(\"color corrected\", np.mean(img[:,:,:3]), np.min(img[:,:,:3]), np.max(img[:,:,:3]))\n",
    "#     plt.imshow(img)\n",
    "#     plt.show()\n",
    "    \n",
    "    fake_img = draw_fake(img, random_img, ordered_p_fake)\n",
    "    return fake_img, img, numberpalte, ordered_p_fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ac4de286",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                    | 6/12000 [00:00<24:07,  8.29it/s]/tmp/ipykernel_150740/1468369858.py:17: RuntimeWarning: divide by zero encountered in float_scalars\n",
      "  l = (lStdTar / lStdSrc) * l\n",
      "/tmp/ipykernel_150740/1468369858.py:18: RuntimeWarning: divide by zero encountered in float_scalars\n",
      "  a = (aStdTar / aStdSrc) * a\n",
      "/tmp/ipykernel_150740/1468369858.py:19: RuntimeWarning: divide by zero encountered in float_scalars\n",
      "  b = (bStdTar / bStdSrc) * b\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 12000/12000 [27:33<00:00,  7.26it/s]\n"
     ]
    }
   ],
   "source": [
    "n = 12000\n",
    "debug = 0\n",
    "RES_DIR = os.path.join(PATH_TO_DATASET, f\"../../../TextDetector/EuUaFrom2004Generated{n}\")\n",
    "res_dir_img = os.path.join(RES_DIR, \"img\")\n",
    "res_dir_ann = os.path.join(RES_DIR, \"ann\")\n",
    "\n",
    "os.makedirs(res_dir_img, exist_ok=True)\n",
    "os.makedirs(res_dir_ann, exist_ok=True)\n",
    "for i in tqdm.tqdm(range(n), total=n):\n",
    "    #np.random.shuffle(images_formats)\n",
    "    for image_format in images_formats:\n",
    "        #print(path_to_images_example.format(image_format))\n",
    "        img = Image.open(path_to_images_example.format(image_format))\n",
    "        gen_img, img_crop, numberplate, np_points = draw_fake_numberplate(img)\n",
    "        #print(numberplate, img.size)\n",
    "        np_img = crop_and_aug_numbeplate(gen_img, np_points)\n",
    "        # WTF? (when some not correct values image backome a one color image )\n",
    "        if np.max(np_img[:,:,0]) - np.min(np_img[:,:,0]) > 50 \\\n",
    "               or np.max(np_img[:,:,1]) - np.min(np_img[:,:,1]) > 50 \\\n",
    "               or np.max(np_img[:,:,2]) - np.min(np_img[:,:,2]) > 50:\n",
    "            if debug:\n",
    "                plt.imshow(np_img)\n",
    "                plt.show()\n",
    "            else:\n",
    "                cv2.imwrite(os.path.join(res_dir_img, f\"{i}_{numberplate}.png\"), np_img[:,:,::-1])\n",
    "                with open(os.path.join(res_dir_ann, f\"{i}_{numberplate}.json\"), \"w\") as fp:\n",
    "                    json.dump({\n",
    "                        \"tags\":[],\n",
    "                        \"objects\":[],\n",
    "                        \"state_id\":\"2\",\n",
    "                        \"region_id\":\"1\",\n",
    "                        \"is_generated\": 1,\n",
    "                        \"size\":{\"width\": np_img.shape[0], \"height\": np_img.shape[1]},\n",
    "                        \"moderation\":{\"isModerated\":1,\"moderatedBy\":\"autogen\",\"predicted\": numberplate},\n",
    "                        \"description\": numberplate,\n",
    "                        \"name\": f\"{i}_{numberplate}\",\n",
    "                        \"count_lines\": \"1\"}, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5922dfa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
